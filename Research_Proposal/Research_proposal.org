# -*- mode:org; mode:reftex; indent-tabs-mode:nil; tab-width:2 -*-
#+TITLE: Research Proposal Master Thesis - Parameters learning in Bayesian Networks
#+AUTHOR:    Marco Hassan
#+LANGUAGE:  en
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}
#+LATEX: \setlength\parindent{0pt}
#+LATEX_HEADER: \usepackage{parskip}

\newpage

* Quick Overview on the Master Thesis.

  The Master Thesis deals with Bayesian Networks. This class of models
  belongs to the set of probabilistic models that are gaining interest
  in the recent years.  One of the major issues with the data-driven
  modeling approach that emerged in the last decade is the inability
  of some models to incorporate uncertainty about models and
  predictions cite:ghahramani15_probab_machin_learn_artif_intel.

  Bayesian networks and graphical models
  cite:ben-gal08_bayes_networ,koller2009probabilistic,Larra_aga_2011
  have gained in this sense a lot of attraction due to the possibility
  of addressing both of the problems mentioned above. In fact, these
  two issues are a key inhibitor to the deployment of data driven
  solution in many practical fields cite:Kl_s_2018.

  When modeling Bayesian Networks three major questions arise:

  1. Representation/Structure - i.e. the decision on how to model the
     problem at stake. 

  2. Inference - i.e. the task of computing the
     probabilities of events given some observations in the network.  

  3. Learning - i.e. the task of selecting in a data driven way either
     the structure or the parameters of the network - or eventually
     both.

  All of the three tasks have been extensively analyzed in the
  literature. A general overview can be found in
  cite:koller2009probabilistic. Despite of this there is a continuous
  expansion of the knowledge in the matter as the three elements above
  encompass and integrate many scientific research fields spanning
  optimization, probability theory, graph theory, information theory
  and statistics.

  In this sense, my Master's Thesis will try to further contribute to
  the expanding literature concerning the Learning task. While it will take the
  problem of model representation and the structure of the network as
  given, it will try in collaboration with IBM Research to address the
  problem of parameter learning in Bayesian Networks.

  In particular the Thesis will focus on a new field of research that
  is being currently explored at IBM Research Europe: the topic of
  Parameter Learning in Bayesian Networks under uncertain evidence
  cite:Wasserkrug_all.

  As mentioned by cite:Wasserkrug_all, will soon
  be published in the AAAI journal:

  #+begin_quote
  In contrast to the case of missing evidence, which is used when there
  is missing knowledge about the values of some random variables,
  uncertain evidence is usually introduced whenever there is knowledge
  about the value of the random variable, but the observational
  process is unable to clearly report a single state for the observed
  variable.
  #+end_quote


  In simple words the type of uncertain evidence that the Thesis will
  address is the one where there is some information about the state of
  a variable in the network but we might not have enough guarantees to
  report a single realization and we rather associate a set of
  likelihood probabilities to the possible variables realizations. In
  fact, this is the likelihood evidence as described in cite:Mrad_2015.

  While cite:Wasserkrug_all proposed a first solution to deal with
  such likelihood evidence at the time of parameter learning in
  Bayesian Networks, many questions remained open in their study. Some
  of such open questions are results about numerical properties of the
  method and questions about the way through which such method can be
  applied to other learning settings.  This second point will be the
  focus of the Thesis. It will research ways to deal with likelihood
  evidence not just under a MLE learning approach but rather also in a
  full Bayesian Learning approach. It will therefore deal with an
  application of the extended EM to the case of MAP parameter
  estimation in the case of a full Bayesian approach and it will question
  how and whether the properties of convergence and correctness
  apply in this setting.

  On the top of it, the Thesis will question whether it is possible
  to extend such adapted EM to other settings such as the one of
  learning from incomplete data with qualitative influences as in
  cite:Masegosa_2016.

  In conclusion the Thesis will try to further investigate the
  possibility of learning parameters in Bayesian Networks under
  likelihood evidence and will try to question the extent to which it
  is possible to generalize the approach proposed by
  cite:Wasserkrug_all to other important settings such as learning via
  a full bayesian approach and learning under qualitative
  influences. All of that will be done both at a theoretical level as
  well as in an empirical way by testing and expanding on the
  open-sourced [[https://github.com/radum2275/merlin][Merlin library]].

* Tentative Schedule

+-----------------------+--------------------------+
|Week/Month             |Activity                  |
+-----------------------+--------------------------+
|December - March       |Literature Review and Get |
|                       |up and Running with       |
|                       |Bayesian Networks.        |
+-----------------------+--------------------------+
|15/03 - 21/03          |(Literature Review and    |
|                       |Code Base)                |
|                       |                          |
|                       |Understand Merlin and Code|
|                       |Base / Continue Literature|
|                       |Review: approximate       |
|                       |inference methods and EM  |
|                       |with missing evidence and |
|                       |Bayesian Prior.           |
+-----------------------+--------------------------+
|22/03 - 28/03          |(Literature Review and    |
|                       |Code Base)                |
|                       |                          |
|                       |Understand Merlin Code    |
|                       |Base and Literature       |
|                       |Review. Collect more      |
|                       |evidence on studies       |
|                       |dealing with uncertainty  |
|                       |in Bayesian Networks.     |
+-----------------------+--------------------------+
|29/03 - 04/04          |(Literature Review)       |
|                       |                          |
|                       |Collect more evidence on  |
|                       |studies dealing with      |
|                       |uncertainty in Bayesian   |
|                       |Networks and on           |
|                       |applications of EM        |
|                       |algorithm for MAP         |
|                       |estimation of Posterior   |
|                       |Parameters Distribution.  |
|                       |                          |
+-----------------------+--------------------------+
|05/04 - 11/04          |(Literature Review)       |
|                       |                          |
|                       |Collect more evidence on  |
|                       |studies dealing with      |
|                       |uncertainty in Bayesian   |
|                       |Networks and on           |
|                       |applications of EM        |
|                       |algorithm for MAP         |
|                       |estimation of Posterior   |
|                       |Parameters Distribution.  |
+-----------------------+--------------------------+
|12/04 - 18/04          |(Literature Review)       |
|                       |                          |
|                       |Collect more evidence on  |
|                       |studies dealing with      |
|                       |uncertainty in Bayesian   |
|                       |Networks and on           |
|                       |applications of EM        |
|                       |algorithm for MAP         |
|                       |estimation of Posterior   |
|                       |Parameters Distribution.  |
+-----------------------+--------------------------+
|19/04 - 25/04          |(Write Down and           |
|                       |Crystallize/make the      |
|                       |point)                    |
|                       |                          |
|                       |Start writing Introduction|
|                       |and Literature Review     |
|                       |Chapter. Start            |
|                       |implementing Bayesian     |
|                       |Prior Parsing in Merlin.  |
+-----------------------+--------------------------+

\newpage

+-----------------------+--------------------------+
|Week/Month             |Activity                  |
+-----------------------+--------------------------+
|26/04 - 02/05          |(Implementation and       |
|                       |Writing)                  |
|                       |                          |
|                       |Continue with Introduction|
|                       |and Literature Review     |
|                       |Chapter. Finish Parsing   |
|                       |Bayesian Prior in         |
|                       |Merlin. Test performance  |
|                       |without missing nor       |
|                       |likelihood evidence.      |
+-----------------------+--------------------------+
|03/05 - 09/05          |(Implementation)          |
|                       |                          |
|                       |Start extending EM for    |
|                       |computing the MAP         |
|                       |estimation of the         |
|                       |Posterior Distirbution in |
|                       |the case of uncertain data|
+-----------------------+--------------------------+
|10/05 - 16/05          |(Implementation)          |
|                       |                          |
|                       |Continue extending EM for |
|                       |computing the MAP         |
|                       |estimation of the         |
|                       |Posterior Distirbution in |
|                       |the case of uncertain data|
+-----------------------+--------------------------+
|17/05 - 23/05          |(Implementation)          |
|                       |                          |
|                       |Continue extending EM for |
|                       |computing the MAP         |
|                       |estimation of the         |
|                       |Posterior Distirbution in |
|                       |the case of uncertain     |
|                       |data. Check at runtime and|
|                       |performance. Check at     |
|                       |theory, do we have        |
|                       |guarantees for            |
|                       |convergenece and          |
|                       |correctness.              |
+-----------------------+--------------------------+
|24/05 - 30/05          |(Implementation)          |
|                       |                          |
|                       |Continue to work on the   |
|                       |implementation. Check also|
|                       |runtime performance and   |
|                       |issue with                |
|                       |convergence. Test with    |
|                       |different priors and      |
|                       |priors hyperparmeters and |
|                       |consider how this affect  |
|                       |convergence and the       |
|                       |results.                  |
+-----------------------+--------------------------+
|31/05 - 06/06          |(Implementation)          |
|                       |                          |
|                       |Consider the algorithm and|
|                       |the necessary inference   |
|                       |step. Try it out in larger|
|                       |Networks and make sure it |
|                       |integreates well with     |
|                       |approximate inference     |
|                       |methods. Understand the   |
|                       |implications for your     |
|                       |results.                  |
+-----------------------+--------------------------+


\newpage

+-----------------------+--------------------------+
|Week/Month             |Activity                  |
+-----------------------+--------------------------+
|07/06 - 13/06          |(Make the Point)          |
|                       |                          |
|                       |Consider how it is        |
|                       |going. Check how it is    |
|                       |going. Where to set the   |
|                       |focus. Where              |
|                       |difficulty. Consider      |
|                       |checking new literature   |
|                       |for 1 week depending on   |
|                       |discoveris during         |
|                       |implementatioin           |
+-----------------------+--------------------------+
|14/06 - 20/06          |(Implementation)          |
|                       |                          |
|                       |Continue with the steps   |
|                       |above. Depending on need. |
+-----------------------+--------------------------+
|21/06 - 27/06          |(Implementation)          |
|                       |                          |
|                       |Continue with the steps   |
|                       |above. Depending on need. |
+-----------------------+--------------------------+
|28/06 - 04/07          |(Implementation)          |
|                       |                          |
|                       |Continue with the steps   |
|                       |above. Depending on need. |
+-----------------------+--------------------------+
|05/07 - 11/07          |(Implementation)          |
|                       |                          |
|                       |Continue with the steps   |
|                       |above. Depending on need. |
+-----------------------+--------------------------+
|12/07 - 18/07          |(Implementation)          |
|                       |                          |
|                       |                          |
|                       |Continue with the steps   |
|                       |above. Depending on need. |
+-----------------------+--------------------------+
|19/07 - 25/07          |(Write Down Results)      |
+-----------------------+--------------------------+
|26/07 - 01/08          |(Write Down Results)      |
+-----------------------+--------------------------+
|02/08 - 08/08          |(Vacation)                |
+-----------------------+--------------------------+
|09/08 - 15/08          |(Vacation)                |
+-----------------------+--------------------------+
|16/08 - 22/08          |(Write Down Results)      |
+-----------------------+--------------------------+
|23/08 - 29/08          |(Write Down Results)      |
+-----------------------+--------------------------+
|30/08 - 05/09          |(Write Down Results)      |
+-----------------------+--------------------------+
|06/09 - 12/09          |(Write Down Results)      |
+-----------------------+--------------------------+
|13/09 - 19/09          |(Summarize and Check)     |
+-----------------------+--------------------------+
|20/09 - 26/09          |(Summarize and Check)     |
+-----------------------+--------------------------+
|27/09 - 03/10          |(Buffer)                  |
+-----------------------+--------------------------+

[[https://marcohassan.github.io/bits-of-experience/posts/bayesian-networks/][Link to Literature Review]].
  
\newpage

bibliographystyle:unsrt
bibliography:../literature/references.bib
