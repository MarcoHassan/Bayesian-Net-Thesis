
* Some general notes on Merlin
  :LOGBOOK:
  CLOCK: [2021-03-29 Mon 17:20]--[2021-03-29 Mon 17:46] =>  0:26
  :END:

** From call with Radu of 18/03/2021

      - To run the code: dataset -> file to

     bte, cte -> exact inference.

     bmw, jjlp -> approximate inference.

     task -> mar (marginal), pr (probability of evidence),

     positive -> if 0 probabilities.

     iterations -> controls approximation schemas

     init-factors -> initialization of parameters.

     lock-factors -> some of the parameters you keep them fixed.

     output format -> json,

     .uai -> format, txt format, to represent graphical model.

     preable -> first entry, number of variables. second row the
     number of conditional parameters for each variables  - third line
     number of factors. 4 and 5th line arguments of function.

     cancer.uai -> see syntax for bayesian network. line 5 - 9 (first
     argument number , last number the child, all of the other parents).


** General Code Structure
   :LOGBOOK:
   CLOCK: [2021-05-29 Sat 16:28]--[2021-05-29 Sat 16:53] =>  0:25
   CLOCK: [2021-05-29 Sat 16:03]--[2021-05-29 Sat 16:28] =>  0:25
   :END:

   #+begin_src plantuml :file ./images/strucutre.png
   @startuml

   /' Class and Variables Declaration '/
   class Merlin
   class EM
   circle main
   class graphical_model
   class cte
   class observation

   /'General Notes and Comments'/

       /'Graphical Model'/
       note top of graphical_model: this parses the uai file into a graph strucutre.

       /'Main'/
       note bottom of main: this is the main runtime. \n it will parse the arguments you pass via CLI\n and instantiate the Merlin engine.

       /'Merlin'/
       note left of Merlin: here is defined the general engine for running the code. \nCreating an engine allows you to initialize your operations \nand pass to it your arguments of the CLI.
       note right of Merlin: note that the souce is in the run function. \nThere depending on the task selected you select \na different algo for the engine. \nSee for instance merlin::em. 

       /'EM'/
       note left of EM: this runs the EM algorithm. \nThe class inherits form graphical models.
       note left: inherits just cte.h. \nAsk Radu if it just works with cte and not approximate inference.

       /'cte'/
       note right of cte: exact inference method. clique tree. 

       /'observation'/
       note right of observation: there is an observation class that deals with all of the observation types. \nyou have to understand this. \nYou also pass it as type to vector. Can you pass **classes** to vectors? \nNote this is not the only class. There are similar things as well for sets etc. so all defined in there.

   /'Diagram Structure and References'/

       /'Calls'/
       Merlin <|-down- main    
       EM <|-- Merlin

       /'Inheritance'/
       graphical_model .. EM
       cte .. EM
       graphical_model .. factors

   /' Class Functions '/

       /'Merlin'/
       Merlin : set arguments, \ni.e. file of interes, \noutput format etc.
       Merlin : read the passed model in the uai format. \nand extracts the factors of the model.
       Merlin : run() - runs the engine; here s.run() runs the aglo
       Merlin : run() - note that when running the engine there is a check \ntest if there is presence for virtual evidence. \naugments graphical model gm in case of presence.
       Merlin : run() - note that when running the engine you instantiate the inference object \n see for instance **merlin::bte s(fs);** in there.
       Merlin : init() - checks paramters and return fals if smth not working

       /'EM Algorithm'/

   @enduml
   #+end_src
   
   #+RESULTS:
   [[file:./images/strucutre.png]]




** Solved Questions

*** DONE ask radu if the em just works with cte inference method to this stage.
    CLOSED: [2021-07-04 Sun 12:44]

    exact inference algorithm. joint-tree.

    in principle you can work with any inference algo - just have to
    change the codebase. at the moment =cte= is hard-coded in the m-step.    

   

*** augmenting network with virtual evidence

    I know that I had already asked it... but don't find my
    answer. why do we have two ways to enlarge the network with virtual
    evidence?

    one in the =merlin.cpp= and one in the =em.cpp=?

    what is the difference in there

    
**** Answer

     In =merlin.cpp= you extend via Pearl method cause that is the way
     you operate for some inference tasks.

     Note that then you will have a new set of factors defined on the
     extended network that you will pass to the engine when making
     inference.

     When running the engine for the em-task you pass the original
     network (see the ~merlin::em s(gm);~ command) and then you
     augment for virtual evidence in case of need in the =em.cpp=
     file. AND THIS ONE YOU DO AT EVERY E-STEP. You do not do it at
     initialization and this is the ultimate reason why you have that
     piece of the code in em and cannot leverage the one in the
     =merlin.cpp= engine. 


*** What are locked Factors in the M-step?

    there is the =m_lockedFactors= variable. Do not manage to properly
    make sense of it. which factors should be locked in the M-step?

    this is a variable of type =set= and you apply to it all of the
    operations belonging to that class.

    I guess that this is for some advanced method they used. but it
    might as well be interesting to me as I might work with it at some
    point.

**** Answer

     so yes; it is not needed as feature for the standard em with
     virtual evidence. it was a requested feature that Radu added.

***** IN-PROGRESS 
     
      check if you can leverage on it when performing probabilistic evidence

     


      
*** what are m_families?

    so =m-families= list/ or set of nodes: node =x= and parents.

    I am not sure that this is the case. I think it might also well be
    the set of the variables present in each clique.

**** DONE 
     CLOSED: [2021-07-03 Sat 16:04]

     You will use this piece of info

     #+BEGIN_SRC cpp 
	size_t n = m_gmo.nvar();
	const std::vector<factor>& factors = m_gmo.get_factors(); 
	size_t m = factors.size();
	m_families.resize(n);
	m_counts.resize(m);
     #+END_SRC

     when computing the M-parameterization with ess. Check at it in
     the code.



* Reminder of c++
  
*** Declaration of pointer

    Note that there are two different things you can declare with the
    =&= operator. You should not confuse these. They look similar but
    are not.

    On the one hand you have =references= on the other one you have
    =pointers=.

    These are not the same and should not be confused.

    So on the one hand you have references. These are implemented as
    follows:

    So you have a reference to x.

    #+BEGIN_SRC cpp :libs -std=c++11 -I./my_code_env/include
    #include <iostream>

    int main(){

      float x = 10.7;

      float& rx = x;

      rx = 8;

      printf("the value of the x is: %f ", x);

      return 0;
    }
    #+END_SRC

    #+RESULTS:
    : the value of the x is: 8.000000

    So you see that when you modify =rx= you are actually also
    modifying =x=. This is the entire idea of reference. You have a
    new variable referencing the other one.

    Note then that there are other subtle things you can do. For
    instance passing a reference with =const= such that you can just
    read the referenced variable but you cannot write it itself.

    See for instance the below that would yield an error.

    #+BEGIN_SRC cpp :libs -std=c++11 -I./my_code_env/include
    #include <iostream>

    int main(){

      float x = 10.7;

      const float& rx = x;

      rx = 8;

      printf("the value of the x is: %f ", x);

      return 0;
    }
    #+END_SRC

    #+RESULTS:

    But check that the following works:

    #+BEGIN_SRC cpp :libs -std=c++11 -I./my_code_env/include
    #include <iostream>

    int main(){

      float x = 10.7;

      const float& rx = x;

      x = 8;

      printf("the value of the rx is: %f ", rx);

      return 0;
    }
    #+END_SRC    

    #+RESULTS:
    : the value of the x is: 8.000000

    Check at pointers next.
    
**** Importance of references in c++

     Note that references are especially important in c++ as with it
     you can specify arguments to pass to functions.

     It is actually a fun idea. so you see that there is the
     difference that you do not have to pass a variable do the
     operations and *return* the object at the end of the function
     with the performed operations and finally assign it again to the
     memory. you save some operations in this sense.

     See also the second benefit of passing by reference:

     #+begin_quote
     a function can use the reference parameter to return multiple values to the calling
     function. Passing by value allows only one result as a return value, unless you
     resort to using global variables
     #+end_quote

     Such that it is immediate to see why the above is especially
     important that is straightforward. You can perform operations on
     *Multiple values*
     
     Check for instance the following:

    #+begin_src cpp
    #include <iostream>

    void test( float& a, float& b) { ++a; ++b;}

    int main(){

      float x = 10.7;

      float y = 1.7;
     
      test(x, y);

      printf("the value of the x, y is: %f, %f ", x, y);

      return 0;
    }
    #+end_src

    #+RESULTS:
    | the value of the x | y is: 11.700000 | 2.7 |

    So you see that the above is working as a charm and a is a
    reference to x in the function.

    Note that the return type of a function can also be a referenced
    object.

    Consider the following:

    #+BEGIN_SRC cpp 
string& message() // Reference!
{
static string str = "Today only cold cuts!";
return str;
}
    #+END_SRC

    Then it is immediate to understand that the above would create a
    reference to a static string with the content defined above.

    Then you can also make the referenced objects returned by a
    function read only by passing the =const= operator in the
    following way so to say:

    #+begin_src cpp
const string& message(); // Read-only
    #+end_src

    It is therefore clear and immediate that c++ as a language allows
    you a much richer modeling set.


*** Pointers and Addresses

    So here is the syntax for defining pointers.

    Recall that a pointer is an expression that represents both the
    address and type of another object.

    You can either note that creating the address operator =&= for a
    *given object* creates a pointer to that object.

    So you can for instance get the address of a defined =int var=
    with the following: ~&var~.

    A pointer points to a memory address and simultaneously /indicates
    by its type/ how the memory address can be read or written to.

    You can as well define /pointer variables/. This are used as
    variables to store pointers references.

    See for instance the following to understand this:

    #+begin_src cpp
    int *ptr; // or: int* ptr; // creates a variable to store a pointer to an int.
    #+end_src

    After declaring a pointer variable, you must point the pointer at
    a memory address. You can do that in the following way:

    #+BEGIN_SRC cpp 
    ptr = &var;
    #+END_SRC

    So once you defined your pointers, as in the following, this is
    generally the syntax you work with

    #+BEGIN_SRC cpp
    #include <iostream>

    int main(){

      double x, y, *px;

      px = &x; // Let px point to x.
      *px = 12.3; // Assign the value 12.3 to x
      *px += 4.5; // Increment x by 4.5.

      printf("the value of the x, px: %f, %f ", x, *px);

      return 0;
    }  
    #+END_SRC

    #+RESULTS:
    | the value of the x | px: 16.800000 | 16.8 |

    So you see that the way you operate with pointers and references
    is the same. What changes is the fact the one is a distinct object
    and the other is not.

    Notice as well the following syntax for pointer declaration:

    #+BEGIN_SRC cpp 
    long *ptr;
    #+END_SRC

    The above essentially means: you create a pointer =ptr= pointing
    to a =long*= i.e. an address with a long value. This is it essentially.

    [[file:images/Bildschirmfoto_2021-03-28_um_16.58.48.png]]

    Note that this is the difference among adress reference &variable
    and pointer. A pointer is a separate object. It can changes
    referenced object. If you declare a reference when initializing a
    variable say =a = &x= you are creating an alias for the object
    x. This reference cannot change at a later point. and the variable
    has not an address in memory that references =a= itself. This is
    different when working with pointers.

    often references are used when declaring functions. these are
    passed as arguments. as you do not have to pass entire objects to
    the function then but rather you point to the objects of interest
    in memory.


*** Passing by pointer - this is a third option apart from passing by reference and value.

    The idea is the following:

    you declare a function parameter to allow an address to be passed
    to the function as an argument.

    you can then do this as follows:

    #+BEGIN_SRC cpp 
#include <iostream>
using namespace std;
void swap( float *, float *); // Prototype of swap()

int main()
{

 float x = 11.1F;
 float y = 22.2F;

 swap( &x, &y );

 printf("value of x: %f \nvalue of y: %f", x,y);

 return 0;

} 

void swap( float *p1, float *p2) // so notice that you pass a pointer
				 // to x, and then this extract the
				 // value in pointer syntax
{
 float temp; // Temporary variable
 temp = *p1; // At the above call p1 points
 *p1 = *p2; // to x and p2 to y.
 *p2 = temp;
}
    #+END_SRC

    #+RESULTS:
    | value | of | x: | 22.200001 |
    | value | of | y: |      11.1 |

    So you can see that this is ultimately extremely close to the
    reference idea in the way it works. It is just an added layer of
    customizing and making your code more granular.    


*** Diff point and references

    References are similar to pointers: both refer to an object in
    memory. However, a pointer is *not merely an alias* but an
    *individual object that has an identity separate from the object* it
    references.

    A pointer has its own memory address and can be manipulated by
    pointing it at a /new memory address/ and thus referencing a
    different object.

    
*** typedef

    this is a simple way to give a new name to your specified
    objects.

    For instance you might rephrase an =unsigned char= to a =BYTE= by:
    
    =typedef unsigned char BYTE=

    


*** constructors and member initialization functions

    #+BEGIN_SRC cpp
factor(factor const& f) :
  v_(f.v_), t_(f.t_), c_(f.c_) {
};
    #+END_SRC

    This is the /member initializer notation/.

    Understand the initializer notation in the following example:

    #+BEGIN_SRC cpp
class Box {
public:
    // Default constructor
    Box() {} // with no elemnts

    // Initialize a Box with equal dimensions (i.e. a cube)
    explicit Box(int i) : m_width(i), m_length(i), m_height(i) // member init list
    {} 

    // Initialize a Box with custom dimensions
    Box(int width, int length, int height)
        : m_width(width), m_length(length), m_height(height)
    {}

    int Volume() { return m_width * m_length * m_height; }

private:
    // Will have value of 0 when default constructor is called.
    // If we didn't zero-init here, default constructor would
    // leave them uninitialized with garbage values.
    int m_width{ 0 };
    int m_length{ 0 };
    int m_height{ 0 };
};
    #+END_SRC

    The general page for understanding constructors [[https://docs.microsoft.com/en-us/cpp/cpp/constructors-cpp?view=msvc-160][is this]].

    Another example for the constructor is this:

    #+BEGIN_SRC cpp 
class TelList
{
private:
  Element v[MAX]; // The array and the current
  int count; // number of elements
public:
  TelList(){ count = 0;}
}
    #+END_SRC


*** size_t

    this is used everywhere in the code. and I needed to make sense of
    it. turns out that it is a standard library method.

    =std::size_t= can store the maximum size of a theoretically possible
    object of any type (including array). A type whose size cannot be
    represented by =std::size_t= is ill-formed (since C++14) On many
    platforms (an exception is systems with segmented addressing)
    =std::size_t= can safely store the value of any non-member pointer,
    in which case it is synonymous with std::uintptr_t.

    =std::size_t= is commonly used for array indexing and loop
    counting. Programs that use other types, such as unsigned int, for
    array indexing may fail on, e.g. 64-bit systems when the index
    exceeds UINT_MAX or if it relies on 32-bit modular arithmetic.


*** arrays

    #+BEGIN_SRC cpp
#include <iostream>
#include <iomanip>
using namespace std;
int main()
{
const int MAXCNT = 10; // Constant
float arr[MAXCNT], x; // Array, temp. variable so like this you
		      // declare both the array as the temporal
		      // variable x as floats.
int i, cnt; // Index, quantity
cout << "Enter up to 10 numbers \n"
<< "(Quit with a letter):" << endl;
for( i = 0; i < MAXCNT && cin >> x; ++i)
arr[i] = x;
cnt = i;
cout << "The given numbers:\n" << endl;
for( i = 0; i < cnt; ++i)
cout << setw(10) << arr[i];
cout << endl;
return 0;
}
    #+END_SRC

    An array contains multiple objects of identical types stored
    sequentially in memory.


    The definition includes the array name and the type and number of
    array elements.

    An example:

    #+BEGIN_SRC cpp
    int myFirstArray[10]; // Array name
    #+END_SRC

    If you want to initialize the arrays directly when you initialize
    them use the following notation passing a list with the elements:

    #+BEGIN_SRC cpp
    int num[3] = { 30, 50, 80 };
    #+END_SRC

    If the array length is explicitly stated in the definition and is
    larger than the number of initial values, any remaining array
    elements are set to zero.

    Locally defined arrays are created on the stack at program
    runtime. Arrays that occupy a large amount of memory (e.g., more
    than one kbyte) should be defined as global or static.

    you can also use arrays to save objects of a given class. this can
    be done in the following way:

    #+BEGIN_SRC cpp 
    <class_name> myArray[10] // where 10 = dimension.
    #+END_SRC

    Such class arrays can be initialized using class arrays

    #+BEGIN_SRC cpp 
    Result temperatureTab[24] =
    { // this is your class array. containing all of the objects you
      // will save in the array in memory.
    Result( -2.5, 0,30,30),
    Result( 3.5), // At present time
    4.5, //  Instead of using a constructor with one argument, you can
	 //  simply supply the argument. The default constructor is
	 //  then called for the remaining elements.
    Result( temp1), // Copy constructor
    temp2 // Just so
    };
    #+END_SRC


    If the size of an array is not stated explicitly, the number of
    values in the initialization list defines the size of the array.

    The public interface of the objects in the array is available for
    use as usual. I.e. you can call methods in the following way:

    #+BEGIN_SRC cpp 
    temperatureTab[2].setTime( 2,30,21);
    #+END_SRC
    

*** vectors

    Vectors are implemented in the =standard template library=.

    Specifically used to work with dynamic data, C++ vectors *may
    expand depending on the elements they contain*. That makes it
    different from a fixed-size array.

    C++ vectors can automatically manage storage. It is efficient if
    you add and delete data often.

    In C++ vectors, automatic reallocation happens whenever the total
    amount of memory is used.

    The syntax for declaring a vector is the following

    #+BEGIN_SRC cpp 
    vector <type> variable (elements)
    #+END_SRC

    So for instance

    #+BEGIN_SRC cpp 
    vector <int> rooms (9);
    #+END_SRC

    Note that the number of elements is optional. this because as
    mentioned we can enlarge or decrease the size of the vectors at
    runtime.

    To resize a vector to match a given shape - i.e. number of
    elements use the following structure:

    #+BEGIN_SRC cpp 
    rooms.resize(shape)
    #+END_SRC    

    #+RESULTS:

    check at the initializer with =-1= and understand what this =-1=
    is exactly doing:

    #+BEGIN_SRC cpp
   #include <vector>
   #include <iostream>

   int main(){

      std::vector<int> hello(8, -1); // so notice that the second argument is the intializator number for the vector. 

      std::cout << hello[2] << std::endl;

      printf("check at the size of this vector: %d", hello[2]);

      return 0;
    }
    #+END_SRC

    #+RESULTS:
    |    -1 |    |     |      |    |      |         |    |
    | check | at | the | size | of | this | vector: | -1 |


*** templates

    check at [[https://www.youtube.com/watch?v=a-3hcS-tEn0][this video]] for understanding templates. basically it is
    nothing new. you just specify blueprints that you can then call by
    name. the properties are then derived for such a template.


*** conditional operator

    I guess this is as in your javascript notes.

    This basically means if the expression =m_evidence.empty()=
    evaluates to true then return =false= otherwise return =true=

    #+BEGIN_SRC cpp 
   bool plainEvidence = (m_evidence.empty() ? false : true);
    #+END_SRC

    
*** some standard functions

    #+begin_src cpp
    std::copy(m_lockedFactors.begin(), m_lockedFactors.end(), 
	    std::ostream_iterator<int>(std::cout, " "));
    #+end_src

    like this you pass each of the locked factors from begin to end to
    the set to the ostream_iterator that would then cout these.
    


*** linker

    puahh.. I recall that was messy. I have to ask again the pc to
    martina to get back all of my notes and build on that. was quite
    annoying with the linker stuff etc. 

    
*** Macros

    There is no big point for Macros to this stage. You can generally
    think as them as global variables and functions. 

    So I mean the point for it is normal. Nothing new.

    You usually define a header file where you define all of the
    Macros relevant for your program. Then you import the header to
    the relevant scripts of your program.

    [[file:~/Desktop/Screenshots/Bildschirmfoto 2021-06-01 um 10.19.00.png]]

    Note that the Macros has benefit in the way they are operated by
    the compiler. This goes low level and is not that interesting to
    me at the moment.

    Note that you can use with =conditional inclusion= when working
    with Macros. The idea is to tell the compiler to just compile the
    section if a the macro is defined...

    #+begin_src cpp
#ifdef name
. . . // Block, which will be compiled
// if name is defined.
#endif
    #+end_src

    Note that you can also work with =#ifndef= there the idea is to
    compile the source block up until the next =#endif= statement.

    See for instance in this sense in Merlin the following strucutre

    #+BEGIN_SRC cpp 
/*
 ,* util.h
 ,*
 ,*  Created on: 24 Mar 2015
 ,*      Author: radu
 ,*
 ,* Copyright (c) 2015, International Business Machines Corporation
 ,* and University of California Irvine. All rights reserved.
 ,*
 ,* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 ,* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 ,* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 ,* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 ,* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 ,* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 ,* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ,* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 ,* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 ,* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 ,*/

/// \file util.h
/// \brief Various utilities
/// \author Radu Marinescu radu.marinescu@ie.ibm.com


#ifndef IBM_MERLIN_UTIL_H_
#define IBM_MERLIN_UTIL_H_

// code.....
// code.....

#endif // re-include
    #+END_SRC


    So I do not see exactly the point of why this is used. but
    probably cause you might call this from multiple places in the
    code such that it is just complied one time.

    This is in fact what happens above as:

    #+begin_quote
    A symbol without a substitute text is often used to identify header files and avoid
    multiple inclusion.
    #+end_quote

    
*** Object Oriented Programming

    This has a quite easy syntax. Think for instance to the following:

    #+BEGIN_SRC cpp 
// car.h: Definition of baseclass Car and
// of the derived class PassCar
// --------------------------------------------------
#include <iostream>
#include <string>
using namespace std;
class Car // Base class
{

private:

  long nr;
  string producer;

public:
  // Default Constructor:
  Car( long n = 0L, const string& prod = "");

  // Access methods:
  long getNr(void) const { return nr; }
  void setNr( long n ) { nr = n; }
  const string& getProd() const{ return producer; }
  void setProd(const string& p){ producer = p; }
  void display( void ) const; // Display a car
};

class PassCar : public Car // Derived class
{

private:
  string passCarType;
  bool sunRoof;

public:
  // Constructor:
  PassCar( const string& tp, bool sd,
	   int n = 0 , const string& h = "");

  // Access methods:
  const string& getType() const{ return passCarType; }
  void setType( const string s) { passCarType = s; }
  bool getSunRoof() const { return sunRoof; }
  void setSunRoof( bool b ) { sunRoof = b; }
  void display() const;

};
    #+END_SRC

    So you see the syntax. You have a function with the class name in
    order to create the class.

    Then you have simply functions; these are the methods of the
    class. As long as they are in the public space they can be
    accessed by the usual =.= notation.

    Notice the following important characteristic of the derived
    classes:

    [[file:~/Desktop/Screenshots/Bildschirmfoto 2021-06-01 um 15.38.32.png]]

    I.e. just the public methods are available in the derived class.

    This ultimately means that methods belonging to derived classes
    only have *indirect* access to the private data members of the base
    class.

    Note that then you can instantiate an object of a class and
    perform operations on it via the following syntax:

    #+BEGIN_SRC cpp 
void PassCar::display( void) const{
  cout << "\nCar number: "
       << getNr();
  cout << "\nProducer: "
       << getProd();  // note that here you do not have to pass the object as being called from within a constructor what this actually evaluates to is with pointer syntax this->getProd()
  cout << "Type: "<< passCarType;  
  cout << "Type: "<< passCarTyp
    if( sunRoof) cout << "yes";
    else cout << " no";
  cout << endl;
}  
#+END_SRC


*** Name Lookup

    This are general questions you should know the answer for. Last
    time at the interview you were tricked by it.

    When the compiler finds a function as the =getProd()= above, the
    usual way to evaluate it is the following:

    - the compiler looks for the name of the method called in the derived class first

    - if the name cannot be found, the compiler walks one step up the
      tree and looks for a public method with that name.

    This has important consequences, as when defining a derived class
    you can overwrite some methods.

    if a member is redefined in a derived class, it will mask the
    corresponding member in the base class.

    
*** Overloading 
    
    Note that you can have multiple methods with the same name but
    different arguments. Such that you can keep redefining within the
    same class.

    This is termed /overloading/.

    Even if you have redefined a method in a derived class, you can
    still call the method in the parent class calling:
    =bas_class::derived_class();=

    This in the code for a derived class object.

    
*** Object initialization

    Notice that in the classes above you have specified default
    constructors. You can however specify other constructors.

    The constructor of a derived class is required to create an object
    of the derived class type.

    To initialize a constructor for the derived class you must
    pass all of the elements necessary to construct an object of the
    derived class. In this case the two =strings=, one =bool= and one
    =int=.

    #+BEGIN_SRC cpp 
// first version

PassCar::PassCar(const string& tp, bool sr, int n,
const string& hs) /// so notice there that you have to pass everything.
{
 // here implicitly the default constructor is called //

 // then you specify the arguments for your class as follows //
 setNr(n); // Initial values for data
 setProd(hs); // members of the base class.

 passCarType = tp; // Initial values for data memsunRoof = sr; // bers of the derived class
}
    #+END_SRC

    Notice that the above is not the usual recommended method.

    This because of the following. The *default constructor* must be
    available in the base class. Moreover, initialization with
    incorrect values /before assigning live values/ impacts the response
    of the program. I.e. you might get errors in that phase.

    In this sense a better initialization method is the following

#+BEGIN_SRC cpp 
// Second version of the constructors of PassCar
// ----------------------------------------------------
PassCar::PassCar(const string& tp, bool sr, int n,
const string& hs) : Car( n, hs) // so notice that this is how you define the initialization of an object
{
passCarType = tp; // Initial values for data memsunRoof = sr; // bers of the derived class
}
#+END_SRC

    Note that the third way to initialize an object via a class is
    with the following syntax:

    #+BEGIN_SRC cpp 
// Third version of the constructor of PassCar
// ----------------------------------------------------
PassCar::PassCar(const string& tp, bool sr, int n,
const string& hs)
: Car( n, hs), passCarType( tp ), sunRoof( sr ) // so notice the
						// syntax. with a
						// comma separed
						// values and taking
						// the arguments from
						// the first object
{
// There remains nothing to do
}
    #+END_SRC

    #+RESULTS:

    The only thing that you have to understand is that you start
    creating an object passing all of the arguments necessary for the
    base class constructor and then you expand from this core
    outwards.

    Note that in a similar way when the an object is destroyed, the
    destructor of the derived class is first called, followed by the
    destructor of the base class. The reverse order of the constructor
    calls applies.

    Notice the power of =C++= and =Java= with their type declared
    variables. With such constructors defined in the =car.h= file you
    can then instantiate object, for instance as =const=. In such a
    way you might just be able to call reading methods for the
    objects. But when calling methods trying to modify the object you
    get errors.
    
*** Calling Redefined Methods

    Note that when calling a redefined method, defined in multiple
    classes, you would actually access the method of the class the
    object belongs to.

    Nothing new in this sense and makes totally sense.

*** Implicit Conversion among Objects

    Note that when you have objects of derived classes you have
    implicitly defined the characteristic of the object belonging to
    the base class - so to say.

    In this sense it is interesting that you can define methods that
    access the base object from an object instantiated from the
    derived class.

    Think for instance to the following strucutre:

    [[file:~/Desktop/Screenshots/Bildschirmfoto_2021-06-08_um_18.12.49.png]]

    This is a very interesting use case in that the above allows you
    to access an object of base class from an object of the derived
    class.

    So given this possibility the question is /when the conversion
    takes place/?

    And basically there are the following cases where the conversion
    takes place:

    - when you assign derived objects to baseclass objects

    - pointers and references *to the base class*

    You can see an example in the picture above. There you see that
    you pass by reference as in the image above is the following: you
    are in fact creating a reference to a in the form of an object of
    base class. And note that the above works well even in the
    arguments of a function - but recall in this sense the peculiarity
    of c++ when you pass objects in there. 

    The other mentioned possibility is the one of assigning directly
    to an object of the base class. Think for instance to the
    following:

    #+BEGIN_SRC cpp 
Car auto;
PassCar bmw("520i", true, 4325, // derived class
"Bayerische Motorenwerke");
auto = bmw;  // convert derived class object to base class object
    #+END_SRC

    The last method - the one of pointer is the more annoying.

    There the idea is to pass the address of derived class object and
    set a pointer of *base class* to it.

    Then through such a pointer you will just be able to access base
    class methods with that weird arrow =->= notation.

    Check the following to understand properly:

    #+BEGIN_SRC cpp 
Car* carPtr = &cabrio;  // cabrio object of derived class

carPtr -> display(); // display method of base class.

carPtr->setSunRoof(false); // Error; method of derived class. cannot be accessed.

// Note that the following is also an error
PassCar auto; // derived class
auto = *carPtr; // Error! Pointer to derived object; true. But of **Base** class
    #+END_SRC

    It is also possible to downcast. However this is not
    recommended. *Avoid it*.

    There you have to make the casting explicitly. Check at it online
    in case of interest.


** TODO Finish the two tomorrow    
    

*** Polymorphism

    That is plenty in this project is the idea that depending on the
    method arguments (with possible overloading) the method performs
    different tasks.

    Come from greek /multiform/. so the idea is that you specify in a
    class higher in the hierarchy a virtual method. You specify the
    method but you do not specify the actual implementation of
    it. I.e. you do not go in the implementation of it but rather keep
    it open. I.e. you specify that for this general class category
    such method must exist but you do not specify a particular
    functional form of it as not being possible. Think for instance at
    the classical example of the =area= of a general class =shape=. Of
    course it is not possible to provide a functional form to the
    =area= of a =shape= as being the latter an abstraction. 

    Then, how you work when working through polymorphism is by
    guaranteeing that the derived classes from the class implementing
    the virtual method specify an exact execution for such virtual
    method.

*** Data Abstraction

    Here the idea is to create a class describing the objects.
    

** understand how you pass structure and evidence
   
   So basically the structure on how you pass things is separate and
   well differentiated.

   You pass the network itself with the associated CPT in the =.uai=
   file.

   You pass the evidence on which to update your parameters via the
   =.evid= files.

   Finally you pass the virtual evidence via the following file format
   =.vevid=

   The way you pass the parameters is described in the [[file:merlin/README.md][Readme]].

   so the meat is all here:
   



*** uai format
    :LOGBOOK:
    CLOCK: [2021-03-29 Mon 15:23]--[2021-03-29 Mon 15:49] =>  0:26
    :END:

    to understand the uai format refer to [[https://www.cs.huji.ac.il/project/PASCAL/fileFormat.php][this source]].

    consider now [[file:merlin/data/ChestClinic.uai][this file]]. this is the chestclinic file in the merlin
    project.

    I will discuss the notation of this here once more.

    so there are essentially two sections in this kind of files.

    the first section denotes the structure of the network. then in
    the second you specify the CPT entries.

    so for the first section the situation can look as follows:

    The first integer in each line specifies the number of variables
    in the clique, followed by the actual indexes of the variables.

    #+begin_example
BAYES                 // first line always specify the type of graphical model: bayes or markov
8                     // the number of variables in your model
 2 2 2 2 2 2 2 2      // the number of possible outcomes per variable -> so here all binary
8                     // the number of *factors*
 1 3                  // the first number represents the number of variables per factor - i.e. the scope of the factor
 2 0 1                // so here you have two variables involved for the factor.  
 3 4 2 5              // the other numbers that follow specify which variables are involved for each factor.
 3 1 5 7              // the variables are represented by the numbers, which represent the index of the variables
 2 0 2                // in the 2 2 2 2 .... 2 above. the index starts from 0
 1 0                  // so for instance this represents the first variable above. 
 2 3 4                
 2 5 6                // last entry is the child. the previous are parents in CPT
    #+end_example

    Then in the second part you specify the actual CPD of the
    factors. 

    For the specific case you would have the following:

    #+begin_example
2   // this is the number of entries in the CPT for each factor. 
 0.01 0.99  // this follows the structure above. i.e. the first entry is for the third factor etc.

 [x_4 = 0 is 0.001]

4
 0.6 0.4 0.3 0.7  // have just to understand how these are expressed. here is where the little Endian cicks in.

8
 1.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0

// x_5 = 0, x_3 = 0, x_6 = 0
// x_5 = 0, x_3 = 0, x_6 = 1  // so here you always change the last one and the order stays the same as line 470.
                              // go from right to left.

// then this notation is changed in the factor.h to bigEndian which would be as follows. 

// so here the definition is the following: Tuples are implicitly assumed in ascending order,
// with the *last variable in the scope* as the 'least significant' i.e. the one you change faster. 
// so in the above for instance you have three variables x_5, x_2, x_4. Then you understand that here
// x_5 is the least signigicant. x_2 the most significant.
// this means that for the above you should read it as follows:
// [x_5 = 0, x_4 = 0, x_2 = 0]
// [x_5 = 1, x_4 = 0, x_2 = 0]
// [x_5 = 0, x_4 = 1, x_2 = 0]
// [x_5 = 1, x_4 = 1, x_2 = 0]
// [x_5 = 0, x_4 = 0, x_2 = 1]
// [x_5 = 1, x_4 = 0, x_2 = 1]
// [x_5 = 0, x_4 = 1, x_2 = 1]
// [x_5 = 1, x_4 = 1, x_2 = 1]

// so you see LittleEndian = least significant variable changes the fastest.

8
 0.9 0.1 0.8 0.2 0.7 0.3 0.1 0.9

4
 0.1 0.9 0.01 0.99

2
 0.5 0.5

4
 0.05 0.95 0.01 0.99

4
 0.98 0.02 0.05 0.95
    #+end_example


*** DONE understand the big-endian to little endian trasformation in the c++ document.
    CLOSED: [2021-06-26 Sat 15:15]
    :LOGBOOK:
    CLOCK: [2021-05-29 Sat 15:03]--[2021-05-29 Sat 15:28] =>  0:25
    :END:

    check at the code described above. paste the code and make small
    experiments to be sure you understand this.

    then given that you understand all of this, you can create files
    as in the =.uai= notation where you can pass the hyperparameters
    for each node.

    quite complex piece of code.

    work in the following alternative way:

    (i) start from the em algorithm.. understand all of the sequence
    of functions that are called. understand just that code and forget
    about the rest. use a reverse engineering technique in this sense.

*** .evid

    Evidence is specified in a separate file. This file has the same
    name as the original network file but with an added =.evid=
    suffix. For instance, problem.uai will have evidence in
    =problem.uai.evid=.

    the syntax is the following:

    #+begin_example
1 // first line => number of evidences samples
2 1 0 2 1 // evidence in each sample, will be written in a new line. first entry = number of observed variables.
          // then pairs. (<variable>, <value>) 
    #+end_example

    So in the example above you would specify that you observe just
    two observations x_2 and x_3 (recall that indexing starts at 0).

    where x_2 = 0, x_3 = 1.
    

*** .vevid

    same idea here. same structure just you have likelihoods instead
    of plain observations.

    see for instance for the specific project the following:

    #+begin_example
    2  // number of evidence
    1 2 0.6 0.8  // first entry = variable index. second entry = size of domain of variable. other entries 0 likelihoods
    2 2 0.1 0.3
    #+end_example



*** also in this sense.. how is the flow evidence -> parameters -> uai.

    cause theoretically this is how you would work. note the following
    solution and interpretation.

    apparently you need both. then you have the =--init-factors= entry
    to overwrite the parameters that you are interested in and are in the
    =.uai= file (i.e. you can initialize them either uniformly or
    randomly).

    if you do not overwrite I guess that the parameters of the =uai=
    file are just taken as the initializers.

    this is in fact how it works. with the new_thetas. in the em
    algorithm that you compute and then pass to a new graphical_model
    object instantiation.

*** training data

    what is the difference between training data and evidence files?

    evid files used for inference. train for parmaters.


** Parameter for the algorithm

      #+begin_example
   "Order=MinFill" << ","
   << "Infer=CTE" << ","
   << "Iter=" << m_iterations << ","
   << "Debug=" << (m_debug ? "1" : "0") << ","
   << "Threshold=" << m_threshold << ","
   << "Init=" << initMethod;
   #+end_example

   arguments for instantiation the EM.

   - he has a stopping criteria check at each iteration.
   
     

** wmb bucket

   best approximate inference algorithm. notice however that
   approximate inference algorithms were not implemented in the =em=
   algorithm code-base. 



** note that factors are key not graphs 
   
   he said that the graph representation in the code is there but is
   not actually used.

   apparently you convert everything into factor format and then work
   from there.

   there is also this twist that he mentioned in the factor
   interpretation there. check at this file [[file:merlin/include/factor.h]]


* Hyperparameters

** General idea

   I decided to save the input of the hyperparameters in a =.prio=
   file.

   There you will have to specify the hyperparameters for each
   node.
   
*** Hyperparameters Considerations

    yes you need a hyperparameter for each parameter.

    so what you need is the number of parameters in your network.

    Check at the general structure for the /uai file/.

    So it is generally correct; there you pass the parameters of the
    network. think for instance to the many applications where you
    would not require to estimate the parameters but these are taken
    as given.

    So take the exact same structure and replace the parameters with
    the hyperparameters. Keep the same mapping and structure of the
    =.uai= files. That should help you as well as somewhere it must
    hold that.

    An example for the structure is given in [[file:merlin/data/cancer.prio][here]]
    
**** DONE How should you set hyperparameters
     CLOSED: [2021-07-03 Sat 16:06]

     check at the book. there is a theory behind that.

     Should be hyper-observations in any case for the case of
     multinomial-dirichlet distribution. So work with integers. Lower
     integers -> less weight on priors and more easy for current data
     to change and influence the posterior.


*** So think for instance at the following 0.1 example of the hyperparameters text file

    #+begin_example
BAYES
5
2 2 2 2 2
5
1 0
2 0 1
2 0 2
3 2 1 3
2 2 4

2
 1 1

4
 1 1
 1 1

4
 1 1
 1 1

8
 1 1
 1 1
 1 1
 1 1

4
 1 1
 1 1
    #+end_example

    So it is immediate to see from the above that in the following way
    you have for the expectation of any theta in the network:

    $$ E(\theta_{x_i| u_j}) = \frac{\alpha_k}{\sum_k \alpha_k} $$

    And in the specific case 1/#param.

    Now check at the next section to implement the reading function of
    the hyperparameters.

*** OUTDATED - Otherwise you can also set it at parameter at the beginning
    CLOSED: [2021-06-21 Mon 15:19]

    See for instance the =set_init_factor_method= function in the
    =merlin.cpp= file.

    And also all of the other parameters that you set when running the
    merlin engine.

    See =main.cpp=.

    Nonetheless, I think it makes better sense to focus on the file
    solution as there might be quite some parameters if you need
    hyperparameters for each node.


* Reading Process

** Central TO UNDERSTAND - WORKING STRUCTURE - graphical_model
   
   from uai  variable create factors vector.

   fixup at the end: from factor creates nodes and edges. (creates the graph).

   you will not be worked with graph - you work with list of factors
   now.

   so here there is the entire flow: from uai to graphical models to
   factors. here are also all of the functions to add factors, remove
   factors etc.

*** DONE find this exact workflow in the tree. would help you in developing everything
    CLOSED: [2021-06-21 Mon 14:51]

    i.e. where is the =uai= file read in the code?

    I believe that you read the =uai= in the =read_dataset= class. It
    is not that clear nonetheless. where is this function actually
    used?
    
**** Notes

     Note that the reading structure is defined in the
     =graphical_model.h= file.

     There you read a graphical model from an *iostream*. There you
     work with the exact =uai= file structure. So you have to work
     with it.

     So the music for reading the model is in here. With the
     =read_dataset= function in the merlin engine, you in fact call
     the =read= method specified in the graphical model header.

     This occurs in fact in here:

     #+BEGIN_SRC cpp 
bool Merlin::read_model(std::string model) {
	try {
		// Read the graphical model
	  int id = merlin::randi(12345678);
	  std::stringstream ss;
	  ss << "model-" << id << ".uai";
	  m_filename = ss.str();
	  std::istringstream is(model); // here you open a stream to the text file. 
	  if (is.fail()) {
	    std::string err_msg("Cannot open the input model string");
	    throw std::runtime_error(err_msg);
	  }

	  merlin::graphical_model gm;
		gm.read(is, m_positive); // here you actually save and read the graphical model.

		// Clear any previous graphical model
		clear();

		// Store the original graphical model (without evidence)
		m_gmo = gm.clone();

		return true;
	} catch (const std::runtime_error& e) {
		std::cerr << e.what() << std::endl;
		return false;
	}
}
     #+END_SRC

     Note moreover that in the graphical model read function there is
     this conversion from =littleEndian= to =BigEndian=.

     Note that the difference is in the way the factors values are
     mapped to the variables. In the =littleEndian= notation the least
     significant variables (defined as the last variable specified
     when mapping the variables to the factor scope in the "first
     section" of the =uai= file. And in the =bigEndian= it is the
     exact opposite. Make tests to see if that is the case and
     matches.
     
     See in the specific the following bit of code for performing the
     transformation:

     #+BEGIN_SRC cpp 
// Read the factor tables (ensure conversion to ordered scopes)
double fval;
std::vector<factor> factors(ncliques);
for (size_t i = 0; i < ncliques; i++) {
	is >> nval;
	assert(nval == sets[i].num_states());
	factors[i] = factor(sets[i], 0.0); // preallocate memory
	if (m_markov == false) { // for Bayes nets, last variable is the child
		factors[i].set_child(cliques[i].back().label());
	}
	convert_index ci(cliques[i], false, true); // HERE IS THE MUSIC AND CONVERSION; convert from source order (littleEndian) to target order (bigEndian)
	for (size_t j = 0; j < nval; j++) {
		size_t k = ci.convert(j);	// get the index in the factor table
		is >> fval; // read the factor value;
		if (positive_mode) { // force positive values (> 0) if enabled
			if (fval == 0.0) {
				fval += MERLIN_EPSILON; // adjust slightly for numerical stability
			} else if (fval == 1.0) {
				fval -= MERLIN_EPSILON; // adjust slightly for numerical stability
			}
		}

		factors[i][k] = fval; // save the factor value into the table
	}
}
     #+END_SRC
     
**** DONE UNDERSTAND HOW THIS FACTOR TABLE IS EXACTLY CREATED
     CLOSED: [2021-06-21 Mon 14:51]

***** big Endian and little Endian Convention
      
      To understand this understand the following table - we work with
      the =uai= explained in this file.

      So recall that the general structure is the following:

      #+begin_example
      BAYES
      8
       2 2 2 2 2 2 2 2
      8
       1 3
       2 0 1
       3 4 2 5
       3 1 5 7
       2 0 2
       1 0
       2 3 4
       2 5 6
      #+end_example

      Such that you have, from the =uai= file with =littleEndian= notation:

      #+begin_example
      F_3 | P(F_3)
      0   | 0.01
      1   | 0.99

      F_0   F_1 |  P(F_1,F_0)
      0       0 |  0.6
      0       1 |  0.4
      1       0 |  0.3
      1       1 |  0.7

      F_4   F_2   F_5 |  P(F_2,F_4, F_5)
      0      0      0 |  1
      0      0      1 |  0
      0      1      0 |  1
      0      1      1 |  0
      1      0      0 |  1
      1      0      1 |  0
      1      1      0 |  0
      1      1      1 |  1


      .... etc .... other factors ....
      #+end_example

      Now in BigEndian Notation that should be:

      *note first entry still all of 0*

      #+begin_example
      F_3 | P(F_3)
      0 | 0.01
      1 | 0.99

      F_0   F_1 |  P(F_1,F_0)
      0       0 |  0.6
      1       0 |  0.3
      0       1 |  0.4
      1       1 |  0.7

      F_4   F_2   F_5 |  P(F_2,F_4, F_5)
      0      0      0 |  1
      1      0      0 |  1
      0      1      0 |  1
      1      1      0 |  0
      0      0      1 |  0
      1      0      1 |  0
      0      1      1 |  0
      1      1      1 |  1

      F_4   F_2   F_5 |  P(F_2,F_4, F_5)
      0      0      0 |  1
      0      0      1 |  0
      0      1      0 |  1
      0      1      1 |  0
      1      0      0 |  1
      1      0      1 |  0
      1      1      0 |  0
      1      1      1 |  1

      .... etc .... other factors ....
      #+end_example

      Ok perfect. I double checked it with the print statement and
      everything is fine.

      So you indeed make the transformation as in the case above and
      get a new factor structure satisfying =bigEndian= notation. For
      instance for the above you get with the print statement:

      #+begin_example
Factor over [3]: 0.01 0.99
Factor over [0,1]: 0.6 0.3 0.4 0.7
Factor over [2,4,5]: 1 1 1 0 0 0 0 1
Factor over [1,5,7]: 0.9 0.7 0.8 0.1 0.1 0.3 0.2 0.9
Factor over [0,2]: 0.1 0.01 0.9 0.99
Factor over [0]: 0.5 0.5
Factor over [3,4]: 0.05 0.01 0.95 0.99
Factor over [5,6]: 0.98 0.05 0.02 0.95
      #+end_example
      
***** DONE BIG ENDIAN VS LITTLE ENDIAN
      CLOSED: [2021-06-21 Mon 14:50]

      Note that factors are general function mapping from a domain of
      variables (D) to the real numbers. It is therefore a general
      function but it is used in our sense as a map from network
      variables to probability functions. (usually - i.e. if the order is
      meaningful in the sense that the multiplication of factors follows
      the conditional independence structure and factors represent ).

   ///
   /// \brief Factor for graphical models.
   ///
   /// Table based representation of a factor for graphical models. A 
   /// factor encodes a potential (sometimes a probability distribution)
   /// defined over a subset of discrete random variables, called a *scope*, and 
   /// associates each configuration of the variables in the scope with a 
   /// positive real value (sometimes a probability value). The scope is assumed
   /// to be sorted lexicogaphically (e.g., [x1,x2,x3]) Also, the indexing of
   /// configurations in the factor table is assumed to be based on the BigEndian
   /// convention, namely the *first* variable in the ordered scope changes
   /// the fastest, then the *second* variable changes its value and so on.
   /// For example, consider a factor over binary variables [x1,x2,x3].
   /// The corresponding factor table is indexed as follows (internally):
   ///
   /// 0: [0,0,0]    4: [0,0,1]
   /// 1: [1,0,0]    5: [1,0,1]
   /// 2: [0,1,0]    6: [0,1,1]
   /// 3: [1,1,0]    7: [1,1,1]

      factor logic and indexing is different from the =.uai= representation
      and this is described above.

      Note that it is important this piece of code:

      #+begin_example
   The scope is assumed to be sorted lexicogaphically (e.g., [x1,x2,x3])
      #+end_example

      Also, the indexing of configurations in the factor table is assumed to
      be based on the BigEndian, namely the *first* variable in the ordered
      scope changes the fastest, then the *second* variable changes its
      value and so on.

      I.e. for each factor you have a /factor table/ that maps your Val(D)
      to real line. In this table there are all of the possible combinations
      of Val(D). The question is then on how you keep record of these and
      the solution is the BigEndian notation.

      There is a function *convert_index*  - maybe not a function have to
      understand that tomorrow. the syntax is not the one of a
      function.
   
      These are in fact both classes that are defined in this file
      [[file:merlin/include/index.h]].

      So notice that this conversion is done because of the following
      reason:

      #+begin_example
   // BigEndian assumes that the first variable changes the fastest
   // UAI input is assumed to follow the LittleEndian convention, whereas
   // the internal representation of the factors assume BigEndian.
      #+end_example

****** Note that in the factor header also all of the functions for factor summation, entropy etc. are defined.    
  


** DONE Understand the reading process out of the files.
   CLOSED: [2021-06-21 Mon 14:52]

   There is a function in the =graphical_model.h= file. There the
   =read= function is specified.

   Notice that there you pass as a parameter the =is=. Have to
   understand what that exactly is.

   This is a file =istream=. So I think it is a standard input
   =std::istream&= element.

   Notice that you consume a line of the input stream with =>>= each
   time.

   Try to double check that

   #+BEGIN_SRC cpp :libs -std=c++11 -I./my_code_env/include
#include <iostream>
#include <sstream>
#include <fstream>
#include <vector>

void read(std::istream& is, bool positive_mode = false) {

		// Read the header
                bool m_markov;
		size_t nvar, ncliques, csize, v, nval; // here the
						       // type is
						       // size_t. so
						       // you do not
						       // define the
						       // type but you
						       // touch it so
						       // to say,
						       // storing the
						       // maximum
						       // possible
						       // amount of
						       // memory for
						       // that object
						       // in memory.
		std::string st;
		
		is >> st; 
		if ( st.compare("MARKOV") == 0 ) {
		  m_markov = true;
		} else if ( st.compare("BAYES") == 0 ) {
		  m_markov = false;
		} else {
		  std::string err_msg("Merlin only supports the UAI Markov or Bayes file format.");
			throw std::runtime_error(err_msg);
		}

		printf ("%d \n", m_markov);

		////////////////////////
		// Read the Variables //
		////////////////////////
		
		// Read the number of variables and their domains //
		is >> nvar;
		std::cout << nvar << "\n";
		std::vector<size_t> dims(nvar);
		for (size_t i = 0; i < nvar; i++){
			is >> dims[i];
		        std::cout << dims[i] << " ";}

		// check at the output of this chunck to understand
		// how the iostream is interpreted. spaces are
		// interpreted as different chuncks when passing via
		// >>.

		// So then always the same structure. See for instance the next thing:

		/// Read the number of factors and their scopes (scope is a variable_set) ///
		is >> ncliques;
		std::vector<std::vector<variable> > cliques(ncliques);
		std::vector<variable_set> sets(ncliques); // store the set of variables associated to each factor
		for (size_t i = 0; i < ncliques; i++) {
			is >> csize;
			cliques[i].reserve(csize);
			for (size_t j = 0; j < csize; j++) {
				is >> v;
				variable V(v, dims[v]);
				cliques[i].push_back(V);
				sets[i] |= V;   // save the set of variables. you should understand better the |= operator.
			}
		}

		// then in the next chunck you actually process the facotrs.

		// there is again nothing too big to understand you just have to understand the conversion function to bigEndian.
		// try to print it.
		
	}

   int main(){

     std::ifstream file ("./merlin/data/cancer.prio");

     bool m_positive = true; 
     
     read(file, m_positive);

     return 0;
     
   }
   #+END_SRC

   #+RESULTS:
   | 0 |   |   |   |   |
   | 5 |   |   |   |   |
   | 2 | 2 | 2 | 2 | 2 |

   Good so you understand now how to read file.

   You can then expand based on this.

   Should be fine in any case. You just need to understand the order
   through which you understand the input parameters.

   I.e. with the factor structure etc. Go over it tomorrow morning.

   Then basically do the same structure for passing the
   hyperparameters.

   Then just adapt m-step and boom! You are good to go.

   Ok. in this sense; check at the read_dataset function in merlin.

   You can borrow from that. I.e. split by comma and store everything
   to a vector.
   


** DONE Reading function for hyperparameters
   CLOSED: [2021-06-27 Sun 19:40]
   :properties:
   :hearder-args:cpp: :session hello
   :end:

*** Small test for read function and read out of iostream
   
    Note that like this it works. You can save functions in headers and
    get them from there by specifying the =-I= option.

    #+begin_src cpp :libs -std=c++11 -I./my_code_env/include
#include <vector>
#include <iostream>

#include "hello.h"

int main(){

  std::vector<int> input = { 1, 2, 3, 4, 5 };

  // so it is correct yourename the variable later
  input = { 1, 2, 3, 4, 5, 6, 7, 8 };

  // input.push_back([70,80,90]); // error. can just push back objects that respect the vector type in this case vector<int>
  input.push_back(70); // valid

  int h = input[0];

  print(input);

  std::cout << h;

  return 0;    
}
    #+end_src   

    #+RESULTS:
    : 1 2 3 4 5 6 7 8 70 1 0

    So that is basically it now you have to embed it in the code. This
    would be a vector containing the prior hyperparameters, starting
    with the bayesian learning MAP estimator.

    Following the syntax of the code base you should write a function
    of the following shape

    #+begin_src cpp
bool Merlin::read_hyperparameters(const char* filename) {
	try {

		// Read the graphical model
		m_filename = std::string(filename);
		std::ifstream is(filename);
		if (is.fail()) {
			std::string err_msg("Cannot open the input file: ");
			err_msg += std::string(filename);
			throw std::runtime_error(err_msg);
		}
		

                // have to specify and read the input out of the .txt file
		// std::vector<int> input = { 1, 2, 3, 4, 5 };

		return true;
	} catch (const std::runtime_error& e) {
		std::cerr << e.what() << std::endl;
		return false;
	}
}
    #+end_src

    Then adapt the M-step. Keep everything equal. Just use a different
    function for the maximization step.



* understand the em-algorithm

  Note that for the algorithm you will need three components for
  which you have to specify properties/ways:

  - factor initialization

  - inference algorithm

  - m-algorithm (i.e. threshold for convergence , order etc.)

  There are then three main functions in the code.

  One for initializing the algorithm.

  One for running the e-step.

  One for running the m-step.

  One for running the algorithm until convergence.

  We will check all of them in turn next.
   
** Run the Algorithm
   :properties:
   :custom_id: run_algo
   :end:

   So very easy. Just calls the two other methods sequentially and
   stops when the algorithm converged.

   Note that the stopping criteria is given by the improvement in the
   log-likelihood.

   You have to find such likelihood. There is in the e-step. Not in
   the m-step. Makes sense.

   So that the idea is this one in general. You run the inference
   engine and get the likelihood of your network. You compute the
   optimal parameters and iterate.


** Initialize the Algorithm

   so at first checks at the missing and virtual evidence and count
   how many observations of these are present as well as their share
   amount.

   
*** Some notes about init algo 

    then you check which factors are locked. so probably they already
    started to work on something with locked factors. that is
    correct. double checked with Radu.

    then you initialize the CPTs. you can either do this via uniform
    or random method.
    
    #+begin_src cpp
    	// Initialize the CPTs uniformly at random
	if (m_init_method == InitMethod::Uniform) {
		m_gmo.uniform_bayes(m_lockedFactors);
	} else if (m_init_method == InitMethod::Random){
		m_gmo.random_bayes(m_lockedFactors);
	}
    #+end_src

    then there is a section about the initialization of the junction
    tree.

    then it follows a bayes net initialization phase. I will explore
    here next and make some quick notes about it.

    #+BEGIN_SRC cpp 
	// Initialize the join tree -- INFERENCE ENGINE
	m_infer = cte(m_gmo);
	m_infer.set_properties(m_properties);
	m_infer.init(); // initialize the join tree

	// Initialize the families (Bayes nets only)
	size_t n = m_gmo.nvar();  // notice nvar == actual variables
				  // (RV that are present in your
				  // network)
	const std::vector<factor>& factors = m_gmo.get_factors(); // factor table - data structure
	
	size_t m = factors.size();  // total number of factors 4th line in your uai file
	m_families.resize(n);
	m_counts.resize(m);         // you need a sufficient statistics per factor? actually not. understand why this is the case here.
	for (size_t i = 0; i < m; ++i) {
	  const factor& f = factors[i];   // one specific factor from the factor table.

	  // have to better understand that with childs how children and parents are defined.
	  // note that the child are so defined in the graphical_model file:
	  //
	  // 	if (m_markov == false) { // for Bayes nets, *last variable* - this is the back function below - is the child
	  //    factors[i].set_child(cliques[i].back().label());
	  //    }
	  int child = f.get_child();
	  assert(child >= 0); // Bayes factor (CPT)
	  variable_set ps; // the parents set
	  std::vector<vindex> pa;

	  // so basically until you do not reach the child you keep
	  // pushing back the nodes to the parents. note that the
	  // label is the unique ID of tthe nodes. i.e. the identifier
	  // starting at 0 in the uai file.
	  for (variable_set::const_iterator it = f.vars().begin();
	       it != f.vars().end(); ++it) {
	    if (it->label() != (size_t)child) {
	      pa.push_back(it->label());
	      ps |= *it;
	    }
	  }

	  // specify a vector of index m_families and assing to each
	  // elemnt of the vector a vector containing all of the
	  // indices of all of the parents of the child in the
	  // network.
	  m_families[child] = pa;

	  // assing 0 to all of the variables. you call the
	  // constructor with the variable set of the factor
	  // class. this constructor returns a vector with the entries
	  // for each variables to 0. Note this are in fact all of the
	  // possible variables realizations. so it si the CPT table
	  // for each factor.
	  m_counts[i] = factor(f.vars(), 0.0);
	  
	  // note that from a test the =vars()=  method jyields the following:
	  // [TEST] Understand the vars() method of the factor vector
	  // [0]
	  // [TEST] Understand the vars() method of the factor vector
	  // [0,1]
	  // [TEST] Understand the vars() method of the factor vector
	  // [0,2]
	  // [TEST] Understand the vars() method of the factor vector
	  // [1,2,3]
	  // [TEST] Understand the vars() method of the factor vector
	  // [2,4]
          // so it is basically a *set* containg the index of the variables associated to a factor.	  
	}

	if (m_debug) {
	  std::cout << "Families:" << std::endl;
	  for (size_t i = 0; i < m_families.size(); ++i) {
	    std::cout << "var " << i << ": ";
	    std::copy(m_families[i].begin(), m_families[i].end(),
		      std::ostream_iterator<int>(std::cout, " "));
	    std::cout << std::endl;
	  }

	  std::cout << "Initial parameters:" << std::endl;
	  for (size_t i = 0; i < m_gmo.get_factors().size(); ++i) {
	    std::cout << " " << m_gmo.get_factor(i) << std::endl;
	  }
	}
    #+END_SRC

*** DONE have to  bbetter understand these parents and child structures
    CLOSED: [2021-06-27 Sun 22:18]

    it seems you are performing vector operations in your m-step and
    then you access the information of interest by indexing.

    that is quite weird cause theoretically there are no vector
    operations in cpp. have to understand that better.

    -----

    SEE ABOVE I N THE CODE CHUNK THE INTERPRETATION
    

** M-step

   Note that I misinterpreted the way the M-step is performed.

   This because I misinterpreted the =m_lockedFactors::find=
   method. See below how it actually works. 

*** Set find and set end.  

    Understand the set_find == set_end. there is this clause that is
    highly misleading.

    It is straightforward to understand the clause in the correct way
    once you read the documentation for the set::find method.

    Notice that when reading online the description for such method you
    can read that:

    #+begin_example
   Searches the container for an element equivalent to val and returns
   an iterator to it if found, otherwise it returns an iterator to
   set::end.
    #+end_example
    
***** OUTDATED

      Ok so this M-step is quite particular as it is highly tight to the
      data structures coming from the =e-step=.

      In this sense it is quite different in comparison to the mental
      framework you used when writing down the theoretical part.

      I will summarize next the practical structure of the M-step here
      and how everything works in tandem with the e-step.

      The idea is the following. You run the e-step before running the
      m-step.

****** DONE Ask radu     
       CLOSED: [2021-06-27 Sun 22:20]

      There at each time you compute the new factors given the evidence
      and save them to a graphical model --> **where is this step??**
      --> then there is a mapping from factors to theta that you would
      leverage.

      Then given this new graphical model, *gm* what you do in the
      M-step is to get the factors that you got in the E-step. From such
      factors you get your =new_thetas=.

      Then you reinitiate the =m_infer= engine with the new
      factors/parameterization such that you are ready to run a new
      inference step in the EM-algorithm.

      That is basically it. You then iterate the cycle.

      ASK RADU WHERE EXACTLY THE CODE IN THE INFERENCE STEP THE
      GRAPHICAL MODEL IS CHANGED AND FACTORS ARE ADJUSTED.
    

****** Outdated - way to the final learning

	To my understanding the key of the the M-step is in the following
	one-liner.

	#+BEGIN_SRC cpp 
    m_infer.reinit(m_gmo.get_factors());
	#+END_SRC

	The idea is that such a function specified by argument as
	reference such that when you call such a function you reinit and
	get the new factors according to the cte algorithm.

	Given such new factors you can then get the new parameters.
    
******* DONE Understand map from expected sufficient statistics to marginal of the factors.
	CLOSED: [2021-06-05 Sat 20:38]

	I think that the issue why you do not see the counts when
	computing the new evidence comes from the following comment:

	#+begin_example
     // Counts factors must be aligned to the theta factors (by construction)
	#+end_example

	BUT THAT JUST COUNTS FOR MULTINOMIAL BY CONSTRUCTION - FOR OTHERS
	YOU MIGHT NEED TO ADJUST THAT COUNT.
     
	So you have to understand that in order to understand how the new
	thetas are parameterized. Otherwise you will always miss a piece
	of evidence.

	Note that this link must in fact exists. Check for instance at
	the following in the e-step:

	#+BEGIN_SRC cpp 
     m_counts[i] += m_infer.get_joint_marginal();
	#+END_SRC

	Such that there must exist a clear relation among the
	joint-marginal and the counts.

******** Solution

	 Note that this is the case as we showed that in the case of
	 simple multinomial CPD the sufficient statistics corresponds to
	 the probability distribution.

	 In this sense you get the joint marginal and the marginal
	 arguments with the evidence and the scope are passed in the
	 previous line:

	 #+BEGIN_SRC cpp 
      for (size_t i = 0; i < m_counts.size(); ++i) {
	variable_set vs = m_counts[i].vars();
	temp.joint_marginal(vs, evidence); // so here is where you pass the conditioning variables and get the necessary conditional probabilities
	 #+END_SRC

	 Check at your thesis text to see that - equation 38.

	 So that is basically it. 

*** Code notes & understanding

    it was correct your interpretation. the music plays in the
    e-step. here you just extract the information and aggregate.


*** M_counts scope & value

    Note that once the scope is clear it will be clear how to extend
    your current model to make it fit.

    I.e. you will make the mapping from the m_counts to the adjusted
    m_counts taking into consideration the hyperparameters.

    Note that you should not confuse the marginalization over the
    probability function that you perform, in order to obtain the
    sufficient statistics and the one you do when summing up the
    sufficient-statistics m_counts. These are two very separate
    things that you should not confound with each other.

    The first one is done in the e-step with the =.joint-marginal()=
    method. The other is done via the =sum= method.

    You should not confuse among the two.
    
**** DONE Scope of M-counts
     CLOSED: [2021-07-03 Sat 16:03]

     so note from your introductory session. it is not the same
     structure the one of m_counts and the one of hyperparameters.

     This means the following:

     - when you create the m_counts you create them per factor -
       i.e. cliques - i.e. per the number of variables combination
       =i..e the third line the uai files=.

     - hyperparameters are also defined per factor. same strucutre so
       they might in fact have the same scope.

     - note that *m_counts* is of type =vector<factor>= so it is a
       vector of factors.

       how are the factors defined? this is a class and its objects
       are instantiated in multiple different ways. The three major
       important elements of such objects are the following:

       - v_ = a /set of variables/ that is associated to the factor.

       - t_ = a /vector of int/ - i.e. the actual values of such factor.

       - c_ = the index of the child variable (this for bayes net).

       given such a basic structure of the factors it is possible to
       understand the m_counts better.

       note that first of the dimension of the m_counts is the same as
       the one of the factors present in the original graphical model

       #+BEGIN_SRC cpp 
const std::vector<factor>& factors = m_gmo.get_factors();
size_t m = factors.size();
m_counts.resize(m);

// then you instantiate all of the different factors entries passing
// the argument for =v_= and =t_=. It follows immediately the strcutre
// of your table.
m_counts[i] = factor(f.vars(), 0.0);
       #+END_SRC

       So that then the entries of the same factors for the
       hyperparameters and the m_counts should be defined in the same
       way over the same scope. They should both follow the BigEndian
       notation.

       Have to double check that.

       Double checked. That is correct. It is the right way to compute
       it and the factor space is the same.

       So notice that the only thing that you need to do is to
       transform the obtained m_counts by adding the hyperparameters
       and subtracting 1 to each entry.

       Notice that there is a parenthesis in the sum in the
       denominator. Do not forget it. 

       #+BEGIN_SRC cpp 
       // try to subtract a single value from a factor and check whether such operator overloader works.
       std::cout << "[TEST] Added Factor: " << std::endl;

       std::cout << 	m_counts[1] + 1 << std::endl;
       #+END_SRC

       Ok - so as long as it is correct it is all fine.

       
     
                         
**** DONE understand factor division BinOpIP - function specific function. find it and check at it in case of need
     CLOSED: [2021-07-02 Fri 10:42]
    

**** DONE you can solve your issue in the following way
     CLOSED: [2021-07-02 Fri 18:30]

     1. get the end-factor table. adjust and check if it makes sense
        your update.

	Original sum factor

     #+begin_example
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 6.5 3.5
Factor sum 
Factor over [0]: 6.5 3.5
Factor sum 
Factor over [1,2]: 2.25 3.25 3.75 0.75
Factor sum 
Factor over [2]: 5.5 4.5
 0: log-likelihood = -23.567
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 6.44923 3.55077
Factor sum 
Factor over [0]: 6.44923 3.55077
Factor sum 
Factor over [1,2]: 2.30849 2.86195 3.81996 1.0096
Factor sum 
Factor over [2]: 5.17044 4.82956
 1: log-likelihood = -19.7573
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 6.24722 3.75278
Factor sum 
Factor over [0]: 6.24722 3.75278
Factor sum 
Factor over [1,2]: 2.18189 2.68989 3.94005 1.18816
Factor sum 
Factor over [2]: 4.87178 5.12822
 2: log-likelihood = -18.966
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 6.0582 3.9418
Factor sum 
Factor over [0]: 6.0582 3.9418
Factor sum 
Factor over [1,2]: 2.08524 2.5875 4.01193 1.31532
Factor sum 
Factor over [2]: 4.67274 5.32726
 3: log-likelihood = -18.5057
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.90088 4.09912
Factor sum 
Factor over [0]: 5.90088 4.09912
Factor sum 
Factor over [1,2]: 2.02288 2.53464 4.04689 1.39559
Factor sum 
Factor over [2]: 4.55751 5.44249
 4: log-likelihood = -18.1486
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.78219 4.21781
Factor sum 
Factor over [0]: 5.78219 4.21781
Factor sum 
Factor over [1,2]: 1.97951 2.51521 4.06304 1.44223
Factor sum 
Factor over [2]: 4.49473 5.50527
 5: log-likelihood = -17.8724
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.70052 4.29948
Factor sum 
Factor over [0]: 5.70052 4.29948
Factor sum 
Factor over [1,2]: 1.94649 2.51453 4.07086 1.46812
Factor sum 
Factor over [2]: 4.46102 5.53898
 6: log-likelihood = -17.6655
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.64854 4.35146
Factor sum 
Factor over [0]: 5.64854 4.35146
Factor sum 
Factor over [1,2]: 1.92041 2.5224 4.07507 1.48212
Factor sum 
Factor over [2]: 4.44281 5.55719
 7: log-likelihood = -17.5142
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.61757 4.38243
Factor sum 
Factor over [0]: 5.61757 4.38243
Factor sum 
Factor over [1,2]: 1.89978 2.53294 4.07763 1.48965
Factor sum 
Factor over [2]: 4.43272 5.56728
 8: log-likelihood = -17.4051
[DEBUG] Begin M-step
Factor sum 
Factor over []: 10
Factor sum 
Factor over [0]: 5.6002 4.3998
Factor sum 
Factor over [0]: 5.6002 4.3998
Factor sum 
Factor over [1,2]: 1.88363 2.54324 4.07936 1.49377
Factor sum 
Factor over [2]: 4.42688 5.57312
 9: log-likelihood = -17.3268
     #+end_example

     2. check if it respects and makes sense.


**** DONE ask radu
     CLOSED: [2021-07-02 Fri 18:30]

     ask about all of that =v_=, =t_= etc... where are they defined.

     ask at radu this piece of code. it does not make sense at all

     #+BEGIN_SRC cpp 
variable_set vx(m_gmo.var(x)); // m_gmo.var(x) seems to return exactly x. makes sense logically. both are index of the variables.

factor sum = m_counts[i].sum(vx); // but it should be a set according
                                  // to this function. understand how
                                  // it is possible note that here the
                                  // music plays. the sum is not
                                  // defined as the sum for the
                                  // variable. it must take the
                                  // variable as argument for doing
                                  // some references but it is not the
                                  // sum of it

// the above is in fact true. check at the definition of the sum operator in the factor.h file
/*
 factor sum(variable_set const& sum_out) const {
 	variable_set t = v_ - sum_out;  // note that v_ is the variable set associated with the factor (m_counts[i] in the above). so t is the set of variables but the chiild.
	return marginal(t);   // recall that the count is defined as the marginal probability. check your thesis notes to see this.
 };

 // the marginal function being called - note that is a bit misleading.  where does the num_states come from. t_ is a table of factors try to print it somewhere

 factor marginal(variable_set const& target) const {
    factor F(target & vars(), 0.0);
    subindex s(v_, F.vars());
    for (size_t i = 0; i < num_states(); ++i, ++s)

    // VERY IMPORTANT //
    // you return the *table entry* (t_[i]). This because the table was updated with the marginal entry in the *e-step*.
    
      F[s] += t_[i]; 
    return F;
  };
,*/


factor temp = m_counts[i] / sum; // that is true it is a table. how
				 // the division is specified for two
				 // factor object is specified in the
				 // factor class. there the / operator
				 // is overwritten. have to understand
				 // binOpIP... ask Radu ok so help
				 // yourself with the theory. like
				 // this it is clear then how the
				 // division is performed. If you have
				 // to implement it yourself in the
				 // code you will still have issues at
				 // the moment.

variable_set scope = th.vars();
factor new_th = th; // copy the previous factor
index_config cv1(scope, true);
config_index cv2(sum.vars(), true);
for (size_t j = 0; j < th.num_states(); ++j) {
  std::map<size_t, size_t> config = cv1.convert(j);
  size_t k = cv2.convert(config);
  if (sum.get(k) != 0) {
    double v = temp.get(j);
    new_th.set(j, v);
  }
     #+END_SRC
	 

**** DONE remove all of the [HELP] entries in the code.
     CLOSED: [2021-07-03 Sat 16:02]


**** DONE add description of .prio in the README
     CLOSED: [2021-07-08 Thu 11:17]
     

**** DONE UNDERSTAND BETTER THE SCOPE OF THE SUM - JUST ALL THE POSSIBLE Y WITHOUT CHANGING PARENTS. UPDATE YOUR THESIS NOT THAT CLEAR THERE.
     CLOSED: [2021-07-03 Sat 16:02]

     this is the local likelihood decomposition property. you did not
     include it sufficiently well in your thesis.

     i.e. so far you just did the general derivation but do it like
     that and you will see that everything will simplify.

     also forgot some parents terms in there.

     work through the *local and global decomposition* properties
     otherwise it becomes quickly messy.

     ok that was wrong. recall that this is exactly the difference in
     the EM method. the two decomposition properties /do not hold/.

     *you should still do some cleaning with the notation as at the
     moment it is still too messy.*

     especially with the parents. I think you can leave everything as
     is but the one of the parents should go away.

     *NOTE* so far all wrong. you are doing the correct
     corrections. did a poor copy and paste. check at the book and
     your notes. does not make sense what you have in there. missing
     completely parents term and did quite some mess there.


**** TODO [#A] note that the likelihood that is written is not correct

     understand the stopping criteria for em in the case of Bayesian
     Learning.

     would have most likely to update it.

     the stopping criteria should be the score-map now.

     this is the objective you are trying to maximize and is the
     measure on which the stopping criteria should be defined.
          
***** TODO the likelihood is specified by the dirichlet-multinomial distribution. have to plug-in the values there given the parameterization

      so understand this logical step.

      so this is the other possibility. as maximizing the posterior is
      the same as maximizing the score-map. it's either or. you can
      choose one of the two.
      
***** TODO understand the likelihood function of the cte algorithm

      there you have a logZ method. you do not get the likelihood in
      such a way.

      you rather get the likelihood when propagating the evidence.

      you have to understand this cte algorithm better.

      I understand then that in the cte the clique algorithm is used
      for propagating the nodes. cannot understand where you get the
      likelihood in there.

      it is the log of the sum of the bielief. which is okey. if the
      factors are normalized etc.

      then only thing that I do not get is how it is how the factors
      are initialized.
      
****** DONE ask radu

       how are the factors in the cte initialized?

       note that in the case of multinomial distribution the factors
       are exactly the /thetas/.

       important is however to understand that in the case of bayesian
       learning the factors change. in the factors you should
       represent the CPDs.

       so in this sense you should modify your factors if you want to
       compute the likelihood based on them and propagate correctly.

       so I think it is correct. if the likelihood is still given by
       the multinomial component then you are fine. you should not
       update it.

       so the first *term is the same* and coming from the likelihood
       component. then you just have to add the prior component,
       which is equally important.


***** DONE ask radu
      CLOSED: [2021-07-16 Fri 18:37]

      you use the =propagate_evidence= method of the cte script to
      perform the cte inference step in the case of evidence. but when
      there is no evidence you use the =run= method of the cte class.

      there is in this sense a division among the two. the =run=
      method is implemented to be used by passing a particular query
      to the algorithm. i.e. it is a specific task in the merlin
      engine.

      note that this propagation of evidence is necessary to get and
      create the new likelihood ratio out of the probabilistic
      evidence.


***** DONE just make an assertion and just allow the case of a single probabilistic evidence.
      CLOSED: [2021-07-17 Sat 11:38]

      
      
** E-step
   
*** DONE Thing to understand
    CLOSED: [2021-07-17 Sat 11:38]

    Here it is all clear just would have to make sense to check exactly
    how the joint-marginal is computed algorithmically and how the
    following is defined and what it returns

    #+BEGIN_SRC cpp 
    m_counts[i] += m_infer.get_joint_marginal();
    #+END_SRC

    This especially as it returns an *entire factor* and not a single
    value.
   
*** General Notes

    Here the inference step is done via big-clique algorithm.

    Understand this is the mental workflow.

    You have a =read_dataset= function in the =merlin.cpp= file. There
    you parse the text file you get with the evidence.

    Then the idea is to create a vector of *observations* and save
    the records in there.

    Notice now the idea of object oriented programming and
    polymorphism. You specify an observation class where you can
    instantiate different observation objects with different
    constructors.

    Then when parsing the file you either get values for the
    realization or likelihood observations that you store in
    respective vectors/variables.

    Then you add to the observations vector passing either such value
    or the likelihood. Depending on what you pass a different
    constructor will be passed.

    There in the constructor the variable =is_virtual= etc. is
    initialized in the correct way depending on which constructor is
    called. And you can then use this information when performing
    your inference tasks.

    Then given this the structure is the following.

    - You first check if virtual evidence is present and in case
      augment the virtual network by adding virtual nodes and creating
      a new graphical model =gm=.

    - After you have a complete network (either because there was no
      virtual evidence or because you augmented the original network),
      you run inference. I.e. you pass the graphical model to the
      inference algorithm. In this case the big-clique algorithm.
      There you propagate the evidence and get the likelihood of the
      network.

      Finally you marginalize over the evidence and the scope to get
      the probability of observing the synthetically completed
      observations.

      This in the case of multinomial distribution has a one to one
      relation with the expected sufficient statistics that you would
      finally use for the new network parameterization.


**** Config Parameters

     Notice then that it follows an entire section, where you treat
     all of the factors indexing according to the bigendian notation
     etc.

     That is a bit annoying next. Understand it cause then you would
     actually be over with the understanding of the =em= algorithm.

     To understand that you have to understand the =index.h= there the
     classes for the indexing of the factors are defined.

     Check at your notes about the bigendian conversion and understand
     if the way you worked with it is the same.

     So that is correct in the =index.h= file you have the
     =convert_index= method that transforms the factor input of the
     =uai= to the bigendian factor notation. This is in fact what it
     is used internally for the algorithm and apparently the input of
     the =uai= file is in littleendian.

     So first of all understand the following: the =thetas= variable in
     the code represent factors not individual parameters.

     You have in fact a loop that gets all of the states from one
     factor.

     #+BEGIN_SRC cpp 
     for (size_t j = 0; j < th.num_states(); ++j) {
       std::map<size_t, size_t> config = cv1.convert(j);
       size_t k = cv2.convert(config);
       if (sum.get(k) != 0) {
	 double v = temp.get(j);
	 new_th.set(j, v);
       }
     }
     #+END_SRC

     The question is now on this conversions and their usage. Note
     that it is also interesting that you do not use the results from
     =cv2.convert= when extracting the content.

***** DONE understand difference among index_config and config_index
      CLOSED: [2021-07-05 Mon 08:54]

      went too deep in the code not necessary. once you understand how
      Big and Little Endian notation works and how they are defined it
      is ok and you will understand such functions and what they do by
      example - little print statements here and there.

      ---------
      OUTDATED

      have to understand that piece of the cake; not that clear to
      this moment. especially the functioning of the first.

      I think that the =index_config= is the part that makes
      everything lexiographically correct. or smth like that

****** index_config

       creates two vectors: =m_dims= and =m_vars=.

       The second, =m_vars= saves the factors. The first =m_dims=
       saves the states of variables sequentially.

       Then the idea is that given such vectors saving all of the
       different states and variables you can call the =convert=
       method to get the variables for a particular index *Represents
       the Index of a Factor*, in BigEndian or LittleEndian notation.

       Then it starts this weird logic in the code. Have to ask it to
       Radu:

       #+BEGIN_SRC cpp 
       if (m_bigendian) {
	       for (size_t v = 0; v < m_dims.size(); ++v) {
		       I[v] = index % m_dims[v];
		       index -= I[v];
		       index /= m_dims[v];
	       }
       #+END_SRC
             

****** config_index

****** start to code everything for next week and then ask for help.

       i.e. code with the same conversion. make smaller checks to see
       how everything is converted. then based on that


****** print the thetas to see the structure of this factor vector.
       looks like a matrix. two entries

       #+BEGIN_SRC cpp 
       new_th.set(j, v);
       #+END_SRC

       understand why this is the case              


    
* IN-PROGRESS Probabilistic Evidence

** Important - Do not do confusion

   Jeffery's Propagation method is not based on any message
   propagating method out of the box. There are algorithm that
   extended it in order to make it work by leveraging the structure of
   Bayesian Networks however that is not the intent originally and out
   of the box.

   in this sense you should not confuse the two and this is why we
   said that you needed to compute the probabilities in the entire
   tree which is very computationally intense - no matter how you do
   that. And here is where you would use BN-inference methods to
   compute the probabilistic structure of all events-ex-ante. Then
   once you have it; forget about the network structure and
   inference. just compute the new probability according to jeffery's
   kinematics.

   so that if you do not use any algorithm you would have to make the
   calculation in all of your tree everywhere the variable with the
   specified posterior is involved.

   very good article to understand [[https://reader.elsevier.com/reader/sd/pii/S0004370204001559?token=83B2399F6380F6BF83D8D490FE49D80E65D35FEA8C7588B499C4752A3E3400BE2134AC3A7C54C5935C0622F81F4A79B7&originRegion=eu-west-1&originCreation=20210704154540][pearl and jeffery's]] - not different
   just different way to implement the two.

   this is why you can also work with pearl as showed by reference 26
   in your thesis.


** Do the single case probabilistic evidence leveraging likelihood evidence

   Seems not too difficult. Check at the algorithms you have in your
   theoretical part.

   So basically have to understand how to get the probabilities for the
   different states realizations.

   ------

   How you understand the thing at the moment:

   you specify the probabilistic evidence for a RV.

   Yeah there is a clear mapping - and when doing it you will quickly
   understand why the last entry is called the =child=.

   So when you specify a probabilistic evidence for a specific factor
   you are in fact specifying it for the *child* and can make this
   exercise of computing the likelihood evidence there.
   
*** How you get the probabilities

    Note that the one you save in your factor tables are not
    probabilities. These you compute exactly depending on the
    parameterization saved in the factor tables.

    Then given that it will be trivial to create the virtual evidence
    and get to the solution.

**** DONE on storing the probability distribution
     CLOSED: [2021-07-11 Sun 10:59]

     here again you can use the graphical model data structure - will
     work well with it and it is always the same type of store.

     ----
     FALSE note that it does much more seem that your likelihood
     evidence is just for one single variable. not for one entire
     factor. so watch out to remember it when you do your
     implementations.

     then you need a different data structure to work with it. can
     also simple work with a vector of int.

     in any case. take your time to think about it and act on it then.

**** DONE understand how you get from parameters to probabilities.
     CLOSED: [2021-07-11 Sun 10:59]

     - I think that in order to get the probabilities for each
       variable realization you should still run inference over the
       entire network.

     - Check if this is indeed the fact. It is check at [[https://www.worldscientific.com/doi/pdf/10.1142/S0218488510006696?casa_token=0371qDcAWtsAAAAA:9G16FxdgNu5sWsJZsjtJrNH-ssM2cWBwOhgTxjLCqO9lxZXlZrIllqq81f73GgBXSUkprXD5eJc][this
       paper]]. There is a good example for the exercise. You might even
       consider of creating the same network to see if you are working
       well.

       ------
       --> correct: you in fact just have to compute marginal
       probabilities for the variables for which you specify the
       probabilistic evidence
       ------
       
       In any case one unit test you might want to start to
       incorporate is that at the end of the propagation the
       probabilistic evidence for the single node that you specified
       should still occur. 

     - Notice how it is also weird. You do not specify the
       *probabilistic evidence* for a factor. In fact you do it for a
       single *variable*. See the example in the paper.


**** DONE understand how you compute the marginal for a variable in the code.
     CLOSED: [2021-07-17 Sat 11:40]

     there are the functions joint-marginal. I guess that you can use
     there.

     These you used to get the probabilities that you then used when
     computing the sufficient statistics in the case of
     multinomial-dirichlet function.

**** DONE understand when you should compute the marignal - check again the paper
     CLOSED: [2021-07-11 Sun 10:59]

     yeah so you have to compute it after the inference step on the
     node of interest.

     i.e. you marignalize there the necessary part.

     
***** DONE [#A] Make the marginalization now.
      CLOSED: [2021-07-17 Sat 11:40]

      the issue is that the joint marginal function is performed via
      the clique algorithm. I am not sure if I understand it
      well. Check at it later. In the meanwhile start to do some
      experiments.

      Note that there is a difference among the probabilities and the
      thetas.

      You should make this more explicit. It is not easy to handle it
      immediately. Cause should you have probabilities in the CPT then
      you could actually immediately write a marginalization function
      by your own.

      So in this sense you should:

      - understand the output of cte - cause when you are computing
        the marginal you compute the probabilities you would be
        interest in.

      - once you have the thetas you can compute the probability of a
        given occurrence depending on the probabilistic structure that
        you imposed on the network. so you can work based on that. 

      - make a test. create a very simple network maybe based on the
        papers where you know that the results should be and expand on
        these.
      
***** Pipeline
      
****** Start with the case of multinomial CPT without prior - i.e. not Bayesian Learning

       there is more straightforward as the probability of each
       occurence is just given by the theta entry in the CPT.

       ---

       I think this is not correct for the following reason: 
       
       i.e. should you also take into consideration the probability
       that the variables for the particular event chicked in? --> yes
       this is why you need to get the probability from *inference*
       methods.

       The entries in the individual tables - i.e. the thetas there
       represent single conditional probabilities. I.e. you assume
       that you are there in the graph.

       So in order to get the overall probability of variable you
       should also consider the probabilistic structure of the
       network.

       This is the ultimate reason why you need an inference step.


****** DONE Get the probability of an event
       CLOSED: [2021-07-17 Sat 11:41]

       I.e. understand how you run the inference engine and get the
       probability of a particular event. 

       I think it should be fine. you do it with the =joint_marginal
       function= of the cte algorithm.

       there you can pass the scope.

       I think that the below should do the job but ask Radu then just
       to stay on the safe side

       #+BEGIN_SRC cpp 
	 variable_set vsz(m_gmo.var(3)); // define the variable you want to get the probability for
	 m_infer.joint_marginal(vsz); // get the marginal for such
				      // variable performing inference
				      // that takes into account the
				      // probabilistic structure of
				      // the network.
	 std::cout << m_infer.get_joint_marginal() << std::endl;  // return
								  // it. note
								  // that
								  // is
								  // a
								  // factor
								  // as
								  // data
								  // structure
								  // so
								  // that
								  // you
								  // operate
								  // on
								  // it
								  // in
								  // a
								  // similar
								  // way
								  // as
								  // with
								  // other
								  // factors.
       #+END_SRC


******* QUESTION ask radu

       The thing that I do not understand is the propagate evidence
       step before that is done in the em-algorithm.

       Where does it come from? what are you propagating?

       given the parameterization of the network it should be possible
       to compute the ultimate probability of interest independent of
       the evidence. should be a separate process. test this.

       - does not work without the evidence propagation; ask Radu why
         this is the case.


****** Get a vector of factors where you store the probability of each event
       
       In any case once the above is cleared you should operate in the
       following way:

       - given the factor with the probabilities for the variable of
         interest extracted - create a new virtual node and propagate
         the likelihood.

       Do this immediately with the probabilities computed in the
       previous section. No matter then what happens you will be
       good.

****** given these probabilities you can then immediately create your likelihood ratio vector

       these by summing up all of the factors related to a given
       variable.

       check at the paper network once more:

       then there you are interested in =dyspnoea= so that if you have
       a probabilistic evidence on there you should sum over all other
       variables and get the probability of getting a particular
       event.
       
****** then from there on is the usual propagation mechanism


**** DONE understand how you specify probabilistic evidence when it is present in multiple places of the graph
     CLOSED: [2021-07-10 Sat 10:08]

     here you just made a lot of confusion. you specify a likelihood
     evidence or a probabilistic statement for one *variable* not for
     *one factor*. In this sense your factor gives an answer 0-1 for
     one variable and on that variable you have your *probabilistic
     statement*.  So in the end you should always assign the virtual
     evidence to the last node.

     ------
     OUTDATED
     
     in theory you should have multiple virtual evidences. you must
     satisfy the statement on the probilistic evidence you impose on
     the particular variable over the *entire network*.
     ------
     
***** DONE ask radu
      CLOSED: [2021-07-04 Sun 16:55]

      OUTDATED - WRONG INTERPRETATION - SEE ABOVE
      
      so understand how this is done. ask radu maybe

      - do you put it in different places? isn't it then the same
	issue as with propagating multiple times?

      - yes I think this is the case. in the normal likelihood it does
	not play a role as they do not have to be guaranteed after propagation.

	----
	Other possibility.
      
      - or maybe it is just good in one place - idea - you assure it
	in one place in the network and it holds then in general?
     

**** DONE change the likelihood and add to it the prior component.
     CLOSED: [2021-07-17 Sat 17:50]

     otherwise you will have convergence in the wrong dimension.

     so understand how you can incorporate the prior component and add
     it to the likelihood in the e-step.

     notice that you cannot modify the general factors as they are
     used to get the correct =expected sufficient statistics=.

     you can add the log-likelihood of the prior by computing:

     $$ \sum log(\theta_{x_i|pa_i}) * a_i - 1 $$


**** TODO note that the BN-IPFP works exactly with clique algorithm that you are working with

     when doing inference. so in this sense the two go in tandem and
     you can leverage the work you already have for solving this.

     very interesting paper the one of 26 that you are basing yourself
     on. lots to learn there. algorithms were proposed in order 
     
***** TODO Why BN-IPFP

      To address this problem, Valtorta, Kim and Vomlel have devised a
      variation of Junction-Tree (JT) algorithm based on IPFP19 that
      utilizes the interdependencies captured in the BN structure.

      The idea is to combine the JT with the IPFP in order to keep the
      computational costs down as it will be easier to compute all of
      the different necessary P(X). These due to the strength of the
      clique algorithm that just with 2 messages manage to cover and
      infer the entire probabilistic distribution of the trees.

      One version of this algorithm works in situation where all
      variables in each j Y are contained in one clique j C in the
      JT. Then the belief update goes iteratively over pthe evidences
      in cycle: in each iteration, ( )j Q C is updated by the
      corresponding ( )j R Y and then the change of ( )j Q C is
      propagated to the rest of the JT by the regular JT method.

      The general situation where a soft evidence may involve
      variables in more than one cliques is dealt with by another
      version called big clique algorithm.

      In this algorithm, when constructing the JT, *all soft evidence*
      nodes (i.e., those variables that are involved in any of the
      soft evidences) are *fully connected with each other* by
      additional undirected edges. After triangulation, all soft
      evidence nodes appear in a single clique (the Big Clique).

      The belief update is done by first updating the big clique using
      all evidences in R by running IPFP to convergence and then
      propagating the resulting distribution of this clique to the
      rest of the JT.

      so you can look around to find that algorithm more specifically
      as you are already running JT it should not be that difficult to
      incorporate that evidence. 
      
****** BN-IPFP-1

       One limitation with these JT based belief update algorithms is
       that they cannot be easily adopted by those using inference
       mechanisms other than JT. they require incorporating IPFP
       operations into the JT procedure, causing re-coding of the
       existing JT inference engine.... *annoying... especially in
       your case*.

       Should be easy to incorporate such method in the code of
       Radu... *do it tomorrow*.

       this algorithm in the paper manages to deal with multiple
       probabilistic evidence by conversion into virtual evidence.

       so it is also interesting to your case. understand how easily
       you can implement this in the merlin engine.

       [[file:~/Desktop/Screenshots/Bildschirmfoto 2021-07-18 um 14.51.46.png]]

       given the above it is quite straightforward to understand how
       you perform the above.
       
****** other more classical methods

       first methods proposed to deal with multiple probabilistic
       evidences.

       1. big clique algorithm:

          requires a different kind of triangulation, but iteration is
          localized to a single clique.

	  - more time efficient

	  - here you have to build a single big clique containing all
            of the different probabilistic evidences.

       2. modified junction tree:

	  e-quires no changes to the junction tree itself, but
          iteration on all variables is required

	  - more space efficient

	  - three steps algorithm. embedding IPFP into the clique
            tree. check at [[https://reader.elsevier.com/reader/sd/pii/S0888613X01000561?token=6ABE0277E793DE61F36239E6C091DD8FBAA0E2B2998F94F70086AB84D068A4B59F1D24AE5FCEFACC489B9A0FBD656E31&originRegion=us-east-1&originCreation=20210720123255][this]] paper - section 4.3.

	  - so this is the usual junction tree with the addition that
            you absorb a Probabilistic Evidence in a clique *using
            IPFP*.

	  - i.e. the difference is that you apply IPFP at clique level
            before propagating using the normal junction tree
            formula. 


       so the idea is simply to say .... look with a single run you
       will not have the property guaranteed as on the second update
       will destroy the necessary formula.... but if you do ipfp you
       guarantee that all of the constraints are fulfilled.

       given that property it follows then that when convergence
       occurs you would actually have the guarantee that the desired
       property holds.

       write down the theory for the above in your thesis and start to
       implement it.

       there are essentially two different methods.

****** TODO write down that is a chess game

       iterative step into an iterative step into an iterative
       step.... computationally it must be massive... think for
       instance the comparison between this multiple-evidence case and
       the single probabilistic evidence case.... In the latter case
       you have an iterative procedure more. Considering that you had
       to embed the IPFP iterative cycle into the e-step (which is
       iterative itself) you would have now 3 iterative steps in a
       matriosca style. difficult to imagine that this can work on
       normal sized networks. 

** Simultation code

   - Yishai A. Feldman; ask him cog-troubleshooting.

   - branch for simulation that used sergey: =uncertainty_experiments=

*** code review for simulation

    =merlin= there you run the binary of the merlin file and you
    interact and interface with it.

    

       
       
** DONE what is the likelihood in the case of bayesian learning?
   CLOSED: [2021-07-17 Sat 17:50]

   understand it.

   note that you hard-coded that 100. it is fine for the algorithm but
   it is not 100% mathematically neat.

** Have understand how the big clique operates in detail

   Read the paper 26. Note that is not exactly the clique method used
   for doing exact inference.

   It is rather the idea of creating a single big clique that
   involves all of the variables for which you specified probabilistic
   evidence in the graph in its factor and get the IPFP Q there and
   propagate then in the entire network based on such a clique. 
   
** Check Again the Code for dealing with Virtual Evidence in the Code

   Note first of all that you deal with virtual evidence in the E-step
   and not in the =init= step.

   That is interesting and important. You already reasoned one time on
   it and why it was the case.... and this is the ultimate reason why
   Radu and the others in their paper talk about creating mulitple
   networks.

   The code to augment the network and deal with virtual evidence is
   the following:

   #+BEGIN_SRC cpp 
// If virtual evidence is present, extend the model with extra variables
if (!virtualEvidence.empty()) {
  graphical_model gm(m_gmo); // copy the current graphical model
  vindex idx = gm.nvar();	// last variable index
  std::vector<factor> nfs = m_gmo.get_factors();

  for (size_t j = 0; j < virtualEvidence.size(); ++j) {
    observation obs = virtualEvidence[j];
    vindex x = (vindex)obs.var();       // virtual evidence
					// variable. so note that the
					// observation data structure
					// saves as well the variable
					// associated with the
					// observation
    likelihood l = obs.likelihood();	// likelihood
    variable xvar = gm.var(x);  // convert from an index to a variable
    variable uvar(idx++, 2);    // have to understand this constructor
				// and the sense of this. you have a
				// variable given by index idx + 1 and
				// two states (the second
				// argument). note idx = num variables
				// so you actually create a "new
				// index". makes sense in this sense.
    variable_set vs;
    vs |= xvar;  // add them probabily if they are not there already
    vs |= uvar;
    factor f(vs, 0.0);   // initialize factor for the created variable_set


    f.set_child(uvar.label()); // set the child of the factor to the
			       // new instantiated variable. the
			       // idx++.

    evidence.push_back(0); // first value of the U variable. you augment the evidence by 0. why?

    dummies.insert(uvar.label()); // keep track of dummy variables - i.e. the virtual nodes

    // create the factor. this logic with the states is how you
    // compute what the contra-example is.
    for (size_t k = 0; k < l.size(); ++k) {
      f.set(k, l[k]);
      f.set(k + xvar.states(), 1.0 - l[k]);
    }

    gm.add_factor(f); // add the extra factor
  }
   #+END_SRC

   Note that is also quite interesting. You add and specify the
   virtual evidence in the evidence file you do not pass a separate
   file. So you should continue to work in such a way. Makes no sense
   to switch.

   In order to understand this better with the =virtualEvidence= data
   structure understand the following.

*** DONE where do you get if the observation is virtual or not
    CLOSED: [2021-07-05 Mon 16:15]

    cannot understand it at the moment. 

    #+BEGIN_SRC cpp 
    if (obs.is_virtual()) {
      virtualEvidence.push_back(obs); // note push_back is a function of the vector operator. it adds obs at the end of the vecctor. 
    } 
    #+END_SRC

    there you get observations from om entries coming from
    =m_dataset=. so there on =m_dataset= it must be somehow described
    how you would use and work with virtual evidence.
    
    
**** Solution

     So understand that this is the mental workflow.

     You have a =read_dataset= function in the =merlin.cpp=
     file. There you parse the text file you get with the evidence.

     Then the idea is to create a vector of *observations* and save
     the records in there.

     Notice now the idea of object oriented programming and
     polymorphism. You specify an observation class where you can
     instantiate different observation objects with different
     constructors.

     Then when parsing the file you either get values for the
     realization or likelihood observations that you store in
     respective vectors/variables.

     Then you add to the observations vector passing either such value
     or the likelihood. Depending on what you pass a different
     constructor will be passed.

     There in the constructor the variable =is_virtual= etc. is
     initialized in the correct way depending on which constructor is
     called. And you can then use this information when performing
     your inference tasks. 


**** Virtual evidence syntax

     #+begin_example
    [0.7;0.5],[0.1;0.4]
     #+end_example

    ~read_dataset~ function finds virtual evidence in the file and
    writes it in likelihood vectors.
   



*** DONE on the m_dataset
    CLOSED: [2021-07-05 Mon 16:15]

    note that you set the m_dataset relevant for training your
    em-algorithm with a method. ~set_dataset~.

    note that there you pass the dataset that was constructed parsing
    int dataset file. i.e. dataset is already the parsed text file
    into a coherent c++ data structure you will use in your program.
    
    there when reading the text file you save likelihood objects in
    likelihood vectors etc.


*** DONE change read_dataset in the merlin.cpp to parse probabilistic evidence
    CLOSED: [2021-07-05 Mon 17:55]

    will have to make a similar exercise for your probabilistic
    statement.

    
**** DECISION

     I have decided to state probabilistic evidence in the following
     way =(0.3, 0.7)= i.e. you have =()= brackets in comparison to the
     =[]= brackets that you have when expressing the likelihood
     evidence.

     then the only question that is left over is on how you would
     parse such evidence.

**** DONE at the moment you have a dataset of size 0. understand why.
     CLOSED: [2021-07-05 Mon 17:55]


*** TODO understand the conversion from likelihood evidence to factor.

    this is the one you ultimately work with when propagating
    everything.
    
**** TODO understand when to update - after inference step theoretically. there each time get a new parameterization.

     and based on it new probabilities after propagating the
     evidence.... then you would compute the likelihood.... and then
     you propagate....

     do you need to do it one time at the beginning? or at each round?
     --> at each round... you also propagate the likelihood at *each
     round* in the e-step!!!!!!!


*** TODO note do not spend too much with the above - not strictly necessary.

    at the end your task will be the following:

    - change the observation constructor to deal with the case of
      probabilistic evidence. decide how you will pass it
      syntactically and how you will deal with it then.

    - convert the probabilistic evidence to likelihood evidence

    - then from here on work in the same way you are working now in
      the presence of probabilistic evidence.
    

* On Experiments on Bayesian Networks
  
*** General Notes

    So the samples are generated according to this =Hugin=
    engine. Unfortunately that is not open-sourced and you need to get
    access to it.
    
**** Understand exactly how they simulate the network

     Is there any example. I saw there this image. So you can select
     for instance a node and select the occurrence and then propagate
     to see how given this realization the probabilistic structure of
     the network changes.

     this is point 8 of the tutorial pdf.

     as you said it is correct they sample based on the probabilistic
     structure of the network.
     
**** TODO ask sergey

     step 3: The only difference is that when they sample dyspnoeaObs
     = True they do not set 1 to the node but rather take the
     *likelihood evidence* as good.
     
     step 4: from the sampled dataset, we created a dataset with
     likelihood evidence by *placing the relevant likelihoods in the
     parent* of the appropriate observation node in the original
     network and *deleting data for the observation node*.

     Note that in the above you do not place a single value but rather
     a vector. I.e. [0.7; 0.3] in the case the dyspnoeaobs child is
     true and [0.3; 0.7] in case it is false. So then you have a
     simple case of a dataset with likelihood evidence.

     So you would ultimately just have data for the node of interest
     with assigned likelihoods to it. In this sense you would have
     sampled from it.

     step 5: create a deterministic dataset where you set =true= for
     the likelihood-evidence variable say =dyspnoea= if its
     observation child is equal to =true=.
     
**** TODO ask radu

      Finally, two experiments were performed with the Child
      network. In the first one (Case 1), uncertainty was as- signed
      to the “Birth Asphyxia” node, which is not a leaf node.

      --> why experiment? it should be well possible theoretically.
      
**** Performance

     In order to measure the goodness-of-fit in all experiments, we
     computed for each CPT the average and maximum absolute
     differences between the *probability estimates and their actual
     values* for each set of values of a CPT of a node and its
     parents.

     -----
     So now you have your sample. You forget the above and start to
     apply your algorithms to the obtained dataset. You will then get
     different parameters estimations for the two datasets.

     Then check how the likelihood adjusted EM algorithm works in
     comparison to the deterministic database. 
     

* General Notes
   
*** Recall that in Pearls method the extended virtual node is always set to true.

*** IMPORTANT: note that the likelihood ratios are passed normalized in the IBM paper... so that they in fact represent probabilities P(obs | x_i)

*** Linear Gaussian Bayesian Networks

    linear
    Gaussian CPDs the local likelihood is given by:


    Performing this task you would have for the log-likelihood of
    linear Gaussian Bayesian:
    
    #+begin_export latex
    \begin{align} \label{eq:like-gaussian-cpd}
    P(X|\theta) = \sum_m -log(\sqrt{2\pi\sigma^2}) \sum_{h[m] \in Val(\mathscr{H}[m])} Q(h[m]) * - \mathbf{\theta}^\intercal \mathbf{\tau(d[m], h[m])}
    \end{align}
    #+end_export            

    Such that

     
**** TODO TO SOLVE THAT PART WORK AS FOLLOWS

***** TODO Look at the chapter 19

      there you can see how the same step of expectation is valid for
      the case of exponential families. there is also clear what the
      sufficient statistics are - recall your course of mathematical
      statistics.

      apparently you use the very same sufficient statistics for the
      exercise of performing your Map projection - see first point
      here above.

      so you get this fish and you can most likely write here the
      theory for the general exponential family. then just a matter of
      generalizing the above.

      there the idea is that you can compute expected sufficient
      statistics, instead of simple sufficient statistics in the very
      same way, i.e. through the posterior P(H | O, \theta_{current}).

      then you can use these when computing the M-step.

      so it is the same story. have just to understand better the
      story of the expected sufficient statistics and how it is
      defined in 17. especially for the empirical distribution and
      not. then understand the inverting process. and from there it
      should be clear.

      the confusing point to this stage is that you will have two
      expected steps which I do not think will be the same.

      I would suggest the following:

      1. compute the MLE for a standard case.

      2. understand what is the sufficient statistics in there.

      3. understand how you can compute the ess from there.

      4. relate everything and make sense of it also in conjunction
         with the piece of information from the chapter 17 in here.

    \newpage
    

    
* How to Run the Engine - Generally the Code

  First compile the entire repository with the help of the Makefile
  you specified in the root directory of your project. run ~make~ in there.

  Then go to the generated binary file. Run it with the necessary
  arguments as specified according the merlin engine =API=. You can
  check at the reference in [[https://github.com/radum2275/merlin][here]].

* TODOs in the code

** DONE there is a connection between the m_hyperparameters graphical model and the normal graphical model.
   CLOSED: [2021-06-26 Sat 14:59]

   this is causing some memory issue. probably they are referencing
   the same memory space and there is some conflict in this sense.

   have to make well sense of this otherwise you will not be able to
   progress.

   so very weird pattern. there must be in some for a connection in
   the memory of the graphical model and hyperparameter model. if you
   comment out the access to one of the two models you can reference
   the other but not both in the same run.
   
*** found the problem

    in the ~read_hyperparameter~ function you were calling the clear()
    method. this was cleaning the =m_gmo= model as it was specified
    like this. therefore then you could not reference it. 

*** try to get the addresses of all of the different objects

    recall the schema of references, addresses and the object stored
    at the addresses.

    work through the c++ and your notes above.

    Did that. Got the two addresses in memory. They are
    *different*. So interestingly must not be that the issue.
    
*** it works now in the plain form. just with hyperparameters it does not work.

    probably you are still doing the parsing of the file in the wrong
    way and you are not entering the if statement. double check that
    and understand.
    
*** check on the internet what the strategies to deal with this issues are. 

*** DONE check in the programs options if the function for the hyperparametes-file makes sense. there might as well be errors.
    CLOSED: [2021-06-26 Sat 14:09]

    not this for sure. minor modification just regarding
    hyperparameterFile.


** DONE implemment a set_hyperparameters method in the engine for the EM.
   CLOSED: [2021-07-03 Sat 16:07]

   have to change the ~merlin::em~ function.  I.e. it should not just
   take the graphical model but as well the hyperparameters. I.e. the
   graphical model where the hyperparameters are saved =merlin::em
   s(gm);=.
   
   Solved by keeping the same constructor and adding a method
   =set_hyperparameter= that is just called in the case
   hyperparameters are passed in the CLI.

   you can then call the variable from the =em.cpp= module. This
   because you specified the m_hyperParameters graphical model storing
   the hyperparameters as a private function.

*** DONE have to understand how to properly use polymorphism.
    CLOSED: [2021-06-27 Sun 14:11]

    there is this issue that you have to construct the em algorithm in
    different ways depending on whether the =hyper= graphical model is
    defined or not.

    have to understand how you can do that because through an if
    statement it is not working. as then the compiler does not
    recognize the object.


    *note that this might not be the best way to solve this:*
    constructors /cannot have a virtual declaration/.
    
*** DONE rewrite the m_step have access in that class to the m_hyperParameters with the graphical model saving the hyperparameters
    CLOSED: [2021-07-05 Mon 15:55]

**** DONE start with parsing the data and get all the factors one by one.
     CLOSED: [2021-07-05 Mon 15:55]

**** DONE make sense of the notation with the Bigendian
     CLOSED: [2021-06-27 Sun 17:02]

     done - added some logging giving you the factor tables you will
     have to work with.
     
***** DONE 
      CLOSED: [2021-07-05 Mon 15:54]

      consider to remove them or added them to the output conditional
      on the =debug flag=.
     

**** DONE understand how you differentiate between the case of hyperparameters and the plain case
     CLOSED: [2021-06-27 Sun 19:27]

     i.e. when to run some piece of code and when not.

     understand how you want to differentiate it in the =em.cpp=
     code. you differentiated it in the =merlin.cpp=, understand if
     you can use the same logic here.

     - you can use by checking if the number of factors of the
       m_hyperParametes is 0. this is the reason for instance why when
       you do not supply the hyperparameters argument your print
       statement is never executed.

     - solve it via polymorphism. if there are no hyperparameters
       specify a set_hyperparameters function for the em algorithm and
       set the m_hyperParameters in that class to =NULL=. no could not
       do it as it m_hyperParameters was an object of graphical_model
       class and could not be set to 0. see this is the difference
       when you program with sum typed languages.

     - so actually solved by introducing a =m_hyper= bool variable in
       the graphical model. this is set to false at initialization for
       all of the models and just modified if hyperParameters are
       supplied. you can then just execute the necessary code upon the
       conditional statement: ~if (m_hyper == false)~
            
      
**** TODO understand the m_factors initialization. will have to modify it.

     - this in the em algorithm implemented in the em.cpp file. Note
       that at the theoretical level you should be fine with it. You
       just need one time the m-counts. this because that stores the
       expected sufficient statistics and you just have one of this.
     
     - have to make sure you add it then to the right place. but you
       are already more less done.

     - in order to properly implement the algorithm you have to
       distinguish among the =factors= and =variables=. One is the
       clique storing a set of variables associated with it. The other
       is the variables themselves. Have to double check the
       notation. You studied it before when checking the construction
       of the factor table.
    

** DONE check if hyperparameter argument passsed. if yes then read hyperparameters otherwise do not.
   CLOSED: [2021-07-03 Sat 16:07]


** DONE should also implement read_hyperparameter method for the binary file and not for path to the file
   CLOSED: [2021-07-15 Thu 15:30]


* Logging code as a help - Might Use it in the future

  This is a big chunck of code that you can use to get the factor
  table and understand how such data structures are used. 

  #+BEGIN_SRC cpp 
	std::cout << "[EM] + start parsing the hyper graphical model  : " << m_order_method << std::endl;

	// TEST - FUNCTION
	// ---------------
	
	// Use the following *helper* function. It was from the
	// write_model function from the graphical_model header
	// file. I guess you can borrow a bit from it.


	// Write the factor tables for the hyperparameters
	if (m_hyper == false){
	  std::cout << "[EM] + HERE factor table hyperparameters STARTS" << std::endl;
	  for (size_t i = 0; i < m_hyperParameters.num_factors(); ++i) {
	    const factor& f = m_hyperParameters.get_factor(i);
	    std::cout << f.numel() << std::endl;
	    for (size_t j = 0; j < f.numel(); ++j) {
	      std::cout << " " << std::setiosflags(std::ios::fixed)
			<< std::setprecision(8) << f[j];
	    }
	    std::cout << std::endl << std::endl;
	  }
	}

	std::cout << "[EM] + HERE factor table graphical model STARTS" << std::endl;
	for (size_t i = 0; i < m_gmo.num_factors(); ++i) {
	  const factor& f = m_gmo.get_factor(i);
	  std::cout << f.numel() << std::endl;
	  for (size_t j = 0; j < f.numel(); ++j) {
	    std::cout << " " << std::setiosflags(std::ios::fixed)
		      << std::setprecision(8) << f[j];
	  }
	  std::cout << std::endl;
	}

	// ok - so the mapping is correct. same structure in big
	// endian as the graphical model. can modify the m_step now
	// according to the thesis material.

  #+END_SRC



  
